{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 11:00:15.840049: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-21 11:00:15.847690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732147215.856201 4087534 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732147215.858775 4087534 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-21 11:00:15.867797: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Loading Dataset...\n",
      "Training Websites: [1309, 228, 51, 563, 501, 457, 285, 209, 1385, 1116, 178, 1209, 864, 65, 61, 191, 447, 476, 1034, 1232, 54, 1149, 407, 1466, 1330, 1436, 1490, 859, 451, 919, 1206, 569, 13, 326, 1429, 865, 696, 1468, 318, 440, 689, 1492, 189, 778, 198, 735, 704, 1236, 541, 88, 940, 1098, 255, 775, 161, 1130, 600, 1287, 1266, 740, 1182, 393, 142, 93, 1354, 466, 592, 163, 1482, 206, 1456, 1462, 928, 1301, 747, 333, 758, 727, 429, 1372, 546, 1399, 1327, 146, 1247, 1300, 350, 1093, 1495, 334, 946, 777, 552, 1310, 1140, 449, 1402, 664, 114, 469, 1486, 646, 821, 548, 135, 432, 1161, 644, 435, 1342, 1022, 810, 1316, 939, 292, 542, 1493, 505, 1478, 1103, 538, 1197, 877, 1195, 817, 741, 1404, 283, 1043, 1010, 186, 96, 224, 313, 1285, 327, 1487, 1221, 130, 788, 781, 1220, 958, 1083, 514, 1133, 23, 234, 1099, 1419, 1312, 1463, 1498, 601, 890, 323, 929, 6, 539, 1025, 365, 1039, 217, 1280, 611, 1308, 1338, 1415, 1477, 1366, 765, 330, 1104, 1086, 1, 1226, 663, 1000, 39, 229, 743, 629, 490, 118, 493, 1393, 1445, 175, 995, 141, 1090, 257, 262, 973, 1125, 338, 1384, 1080, 1242, 866, 433, 1417, 411, 638, 1375, 764, 897, 1059, 924, 247, 507, 460, 131, 692, 43, 1204, 1134, 471, 1205, 1471, 14, 145, 120, 468, 138, 64, 676, 1278, 1052, 487, 570, 994, 438, 1298, 270, 1169, 1180, 968, 497, 1262, 833, 389, 193, 1455, 882, 725, 867, 841, 956, 110, 201, 124, 824, 694, 223, 509, 392, 1258, 1448, 918, 287, 1363, 375, 1269, 947, 511, 154, 907, 1127, 200, 103, 1107, 30, 1484, 484, 340, 832, 1268, 985, 437, 1397, 1277, 337, 776, 4, 799, 543, 931, 584, 1414, 1138, 996, 317, 388, 607, 445, 119, 1186, 1110, 1248, 642, 117, 102, 1196, 976, 1029, 1087, 322, 116, 1040, 164, 380, 140, 139, 481, 826, 245, 1166, 504, 81, 167, 858, 1157, 1070, 647, 534, 418, 643, 488, 1213, 1388, 268, 614, 936, 1175, 148, 19, 938, 1153, 204, 150, 1101, 436, 1036, 1170, 271, 714, 1187, 500, 756, 583, 1344, 1293, 1112, 619, 1356, 16, 1135, 613, 212, 275, 1451, 236, 219, 1435, 1461, 557, 577, 431, 702, 416, 540, 1035, 1322, 1355, 104, 1457, 1253, 566, 90, 7, 683, 267, 536, 1328, 904, 875, 1163, 1320, 1233, 305, 73, 1150, 303, 880, 261, 85, 631, 746, 1263, 732, 430, 1234, 210, 724, 1223, 316, 1225, 332, 362, 844, 50, 367, 680, 843, 508, 1350, 1476, 221, 783, 79, 963, 455, 408, 942, 716, 625, 1434, 456, 48, 395, 816, 672, 1452, 1437, 571, 719, 1371, 818, 678, 56, 1137, 1174, 1339, 1155, 78, 222, 889, 707, 1199, 893, 1047, 1058, 1360, 1426, 521, 1120, 1049, 3, 403, 745, 883, 143, 1273, 1050, 1447, 615, 633, 836, 668, 1332, 605, 260, 1243, 861, 1216, 356, 630, 582, 308, 415, 561, 853, 0, 311, 293, 215, 1460, 804, 593, 621, 670, 329, 1431, 452, 1005, 691, 218, 523, 1092, 812, 922, 982, 815, 753, 173, 674, 86, 290, 527, 679, 648, 634, 343, 95, 838, 974, 769, 240, 688, 1207, 230, 825, 203, 1159, 25, 47, 250, 486, 1073, 870, 786, 74, 1072, 424, 1480, 1392, 589, 199, 1454, 713, 1438, 506, 409, 249, 151, 671, 1453, 5, 914, 768, 881, 1046, 906, 109, 797, 1391, 1367, 180, 823, 712, 530, 475, 1497, 1066, 1481, 868, 1200, 467, 136, 820, 937, 1118, 1055, 572, 609, 324, 773, 912, 453, 627, 834, 736, 913, 516, 1177, 850, 1018, 1071, 162, 761, 1255, 971, 1288, 265, 997, 253, 860, 652, 1420, 784, 796, 533, 496, 641, 244, 281, 450, 1079, 730, 1491, 981, 278, 986, 1364, 553, 82, 1406, 1201, 1048, 1026, 710, 156, 723, 1136, 1418, 965, 417, 1304, 555, 477, 425, 63, 211, 852, 1241, 398, 1235, 598, 1386, 20, 1302, 962, 1045, 1171, 1390, 360, 1109, 771, 399, 1421, 551, 1329, 752, 559, 819, 617, 225, 499, 1075, 279, 446, 1261, 29, 863, 344, 684, 695, 1295, 414, 1374, 169, 478, 1361, 637, 1144, 27, 1190, 606, 1132, 1060, 1449, 1380, 658, 1267, 1275, 472, 1369, 1439, 266, 1469, 335, 216, 465, 1410, 345, 779, 809, 284, 770, 1131, 258, 83, 1185, 1146, 767, 1407, 53, 358, 1111, 665, 70, 667, 41, 772, 31, 903, 1160, 1472, 636, 1377, 894, 129, 1126, 685, 1198, 1343, 1245, 1006, 1074, 1307, 377, 171, 620, 1009, 960, 774, 1179, 1283, 1250, 1433, 26, 319, 857, 693, 384, 406, 1351, 1376, 77, 1219, 1051, 1231, 248, 1124, 959, 1020, 700, 1167, 123, 579, 42, 355, 545, 1208, 677, 379, 862, 518, 1323, 349, 12, 1238, 1411, 108, 443, 370, 650, 470, 803, 1284, 941, 1057, 666, 276, 1389, 848, 495, 851, 984, 749, 274, 1115, 251, 1450, 1383, 461, 955, 1427, 1381, 624, 1259, 802, 1240, 1031, 957, 1091, 999, 1252, 1337, 363, 264, 348, 286, 610, 282, 1428, 10, 529, 195, 87, 1290, 1129, 1151, 568, 246, 1270, 661, 502, 458, 17, 1362, 301, 226, 830, 1444, 1475, 595, 949, 1024, 1121, 926, 352, 943, 1496, 871, 1017, 464, 277, 1345, 1334, 1105, 1440, 197, 1148, 122, 1396, 1123, 196, 1081, 902, 900, 603, 537, 1335, 289, 1378, 1256, 1106, 232, 369, 183, 309, 1279, 1194, 1408, 280, 46, 55, 659, 299, 699, 953, 105, 728, 587, 291, 480, 1317, 1336, 687, 188, 52, 798, 489, 1191, 66, 410, 503, 75, 590, 1479, 155, 152, 576, 1015, 989, 254, 121, 1064, 426, 231, 535, 856, 703, 920, 304, 439, 312, 1485, 101, 1405, 807, 1265, 944, 160, 1183, 177, 565, 76, 574, 2, 1173, 585, 898, 298, 33, 237, 295, 987, 901, 72, 239, 662, 202, 656, 763, 978, 596, 272, 1272, 1108, 580, 828, 314, 921, 1373, 127, 479, 594, 412, 887, 512, 1382, 448, 1038, 40, 442, 748, 256, 1423, 1474, 1352, 21, 1139, 1260, 179, 599, 1004, 801, 185, 878, 1346, 528, 522, 1023, 567, 341, 328, 886, 792, 1021, 717, 168, 1096, 737, 1178, 147, 339, 483, 205, 734, 586, 1042, 18, 1314, 45, 1313, 618, 165, 59, 1069, 1430, 532, 263, 422, 1016, 336, 1063, 651, 988, 1210, 1061, 1368, 905, 519, 909, 387, 934, 320, 800, 837, 681, 1333, 930, 896, 67, 1085, 840, 892, 357, 1158, 62, 626, 1192, 1128, 1251, 1078, 1459, 1100, 159, 698, 1119, 829, 208, 1306, 115, 1422, 58, 1488, 60, 331, 1228, 1054, 1282, 366, 149, 1027, 361, 1202, 578, 427, 1089, 241, 932, 233, 731, 967, 895, 97, 306, 1394, 382, 69, 35, 908, 855, 404, 849, 174, 822, 259, 806, 1325, 144, 371, 744, 300, 296, 1217, 972, 935, 1347, 525, 428, 176, 170, 423, 390, 1379, 1257, 873, 1189, 711, 459, 1044, 1271, 421, 1203, 1473, 22, 910, 242, 1214, 1326, 1398, 726, 1424, 750, 517, 639, 1274, 649, 302, 970, 811, 842, 364, 269, 697, 1483, 1172, 1458, 808, 891, 38, 888, 1395, 1222, 757, 751, 755, 524, 1246, 1011, 273, 194, 378, 721, 1403, 612, 1318, 1412, 1019, 1218, 645, 462, 604, 622, 1053, 1088, 923, 1499, 227, 831, 153, 911, 1353, 166, 28, 975, 628, 1324, 220, 660, 125, 1154, 1188, 560, 92, 1370, 89, 1147, 1237, 1165, 759, 564, 791, 1387, 1012]\n",
      "Training Locations: ['LOC1', 'LOC2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asil0892/doh_traffic_analysis/code/scripts/init_dataset.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.sort_values(by=[\"Location\"], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Website</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.086861</td>\n",
       "      <td>0.690199</td>\n",
       "      <td>0.647933</td>\n",
       "      <td>0.201517</td>\n",
       "      <td>0.207139</td>\n",
       "      <td>-0.031855</td>\n",
       "      <td>-0.316768</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055571</td>\n",
       "      <td>0.160203</td>\n",
       "      <td>0.121677</td>\n",
       "      <td>0.093533</td>\n",
       "      <td>0.09274</td>\n",
       "      <td>0.057062</td>\n",
       "      <td>0.155991</td>\n",
       "      <td>0.109839</td>\n",
       "      <td>0.086282</td>\n",
       "      <td>0.08604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC1</td>\n",
       "      <td>1005</td>\n",
       "      <td>1.095547</td>\n",
       "      <td>-1.585943</td>\n",
       "      <td>0.647933</td>\n",
       "      <td>0.343653</td>\n",
       "      <td>0.207139</td>\n",
       "      <td>-0.031855</td>\n",
       "      <td>-0.316768</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055571</td>\n",
       "      <td>0.160203</td>\n",
       "      <td>0.121677</td>\n",
       "      <td>0.093533</td>\n",
       "      <td>0.09274</td>\n",
       "      <td>0.057062</td>\n",
       "      <td>0.155991</td>\n",
       "      <td>0.109839</td>\n",
       "      <td>0.086282</td>\n",
       "      <td>0.08604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC1</td>\n",
       "      <td>1005</td>\n",
       "      <td>1.095547</td>\n",
       "      <td>0.780047</td>\n",
       "      <td>-1.972790</td>\n",
       "      <td>0.343653</td>\n",
       "      <td>0.207139</td>\n",
       "      <td>-0.031855</td>\n",
       "      <td>-0.316768</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055571</td>\n",
       "      <td>0.160203</td>\n",
       "      <td>0.121677</td>\n",
       "      <td>0.093533</td>\n",
       "      <td>0.09274</td>\n",
       "      <td>0.057062</td>\n",
       "      <td>0.155991</td>\n",
       "      <td>0.109839</td>\n",
       "      <td>0.086282</td>\n",
       "      <td>0.08604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOC1</td>\n",
       "      <td>1005</td>\n",
       "      <td>-1.086861</td>\n",
       "      <td>0.690199</td>\n",
       "      <td>0.647933</td>\n",
       "      <td>0.343653</td>\n",
       "      <td>0.207139</td>\n",
       "      <td>-0.031855</td>\n",
       "      <td>-0.316768</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055571</td>\n",
       "      <td>0.160203</td>\n",
       "      <td>0.121677</td>\n",
       "      <td>0.093533</td>\n",
       "      <td>0.09274</td>\n",
       "      <td>0.057062</td>\n",
       "      <td>0.155991</td>\n",
       "      <td>0.109839</td>\n",
       "      <td>0.086282</td>\n",
       "      <td>0.08604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOC1</td>\n",
       "      <td>1005</td>\n",
       "      <td>1.095547</td>\n",
       "      <td>0.780047</td>\n",
       "      <td>0.183501</td>\n",
       "      <td>-0.828965</td>\n",
       "      <td>-2.083179</td>\n",
       "      <td>-0.031855</td>\n",
       "      <td>-0.316768</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055571</td>\n",
       "      <td>0.160203</td>\n",
       "      <td>0.121677</td>\n",
       "      <td>0.093533</td>\n",
       "      <td>0.09274</td>\n",
       "      <td>0.057062</td>\n",
       "      <td>0.155991</td>\n",
       "      <td>0.109839</td>\n",
       "      <td>0.086282</td>\n",
       "      <td>0.08604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location  Website         0         1         2         3         4  \\\n",
       "0     LOC1        0 -1.086861  0.690199  0.647933  0.201517  0.207139   \n",
       "1     LOC1     1005  1.095547 -1.585943  0.647933  0.343653  0.207139   \n",
       "2     LOC1     1005  1.095547  0.780047 -1.972790  0.343653  0.207139   \n",
       "3     LOC1     1005 -1.086861  0.690199  0.647933  0.343653  0.207139   \n",
       "4     LOC1     1005  1.095547  0.780047  0.183501 -0.828965 -2.083179   \n",
       "\n",
       "          5         6         7  ...       116       117       118       119  \\\n",
       "0 -0.031855 -0.316768  0.824649  ...  0.055571  0.160203  0.121677  0.093533   \n",
       "1 -0.031855 -0.316768  0.824649  ...  0.055571  0.160203  0.121677  0.093533   \n",
       "2 -0.031855 -0.316768  0.824649  ...  0.055571  0.160203  0.121677  0.093533   \n",
       "3 -0.031855 -0.316768  0.824649  ...  0.055571  0.160203  0.121677  0.093533   \n",
       "4 -0.031855 -0.316768  0.824649  ...  0.055571  0.160203  0.121677  0.093533   \n",
       "\n",
       "       120       121       122       123       124      125  \n",
       "0  0.09274  0.057062  0.155991  0.109839  0.086282  0.08604  \n",
       "1  0.09274  0.057062  0.155991  0.109839  0.086282  0.08604  \n",
       "2  0.09274  0.057062  0.155991  0.109839  0.086282  0.08604  \n",
       "3  0.09274  0.057062  0.155991  0.109839  0.086282  0.08604  \n",
       "4  0.09274  0.057062  0.155991  0.109839  0.086282  0.08604  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scripts.init_gpu as init_gpu\n",
    "import scripts.init_dataset as init_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "init_gpu.initialize_gpus()\n",
    "\n",
    "locations = ['LOC1', 'LOC2']\n",
    "\n",
    "print(\"Loading Dataset...\")\n",
    "# load the dataset\n",
    "df = pd.read_csv(\n",
    "    f\"../dataset/processed/{locations[0]}-{locations[1]}-scaled-balanced.csv\")\n",
    "\n",
    "length = len(df.columns) - 2  # subtract the two label columns\n",
    "\n",
    "# get train-test set\n",
    "train_df, test_df, train_web_sam1ples, test_web_samples = init_dataset.get_sample(\n",
    "    df, locations, range(1500), 1200)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "random.seed(42)\n",
    "selected_location = 'LOC1'\n",
    "selected_websites = random.sample(test_web_samples, 100)\n",
    "location_df = test_df[(test_df['Location'] == selected_location) & (test_df['Website'].isin(selected_websites))]\n",
    "X = location_df.iloc[:, 2:].to_numpy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(location_df.Website)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.05, F1 Score:  93.16, Precision:  94.96, Recall:  92.03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9204545454545454,\n",
       " 0.9495556758091045,\n",
       " 0.9202539814873415,\n",
       " 0.9315588838108624,\n",
       " array([[60,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0, 60,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0, 60, ...,  0,  0,  1],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ..., 51,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0, 56,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0, 61]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scripts.classification import evaluate_classification_model\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "evaluate_classification_model(X_train, y_train, X_test, y_test, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check accuracy after reconstruction of vae model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asil0892/doh_traffic_analysis/.venv/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scripts.train_vae import VAE, Sampling, ConvVAE_BatchNorm\n",
    "import tensorflow as tf\n",
    "\n",
    "vae_model = tf.keras.models.load_model(\"../models/vae/ci_vae/ConvBased/domain_and_class/LOC1-LOC2-e880-mse1-kl0.01-cl1.0-ConvBatchNorm-ldim96-hdim128.keras\", custom_objects={'ConvVAE_BatchNorm': ConvVAE_BatchNorm, 'Sampling': Sampling})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7315151515151516"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_recon, _, _ = vae_model(X_test)\n",
    "rf.score(X_test_recon, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7956716417910448"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_recon, _, _ = vae_model(X_train)\n",
    "rf.score(X_train_recon, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain model with reconstructed data and actual data and see if the original accuracy retains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.30, F1 Score:  92.20, Precision:  95.07, Recall:  90.31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9030303030303031,\n",
       " 0.9506717684732965,\n",
       " 0.9030767716687588,\n",
       " 0.9220381447670826,\n",
       " array([[58,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0, 63,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0, 58, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ..., 54,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0, 58,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0, 36]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train_recon, _, _ = vae_model(X_train)\n",
    "\n",
    "\n",
    "X_train_combined = np.vstack((X_train_recon, X_train))\n",
    "y_train_combined = np.hstack((y_train, y_train))\n",
    "\n",
    "# test on actual data\n",
    "evaluate_classification_model(X_train_combined, y_train_combined, X_test, y_test, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7522727272727273"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test_recon, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
