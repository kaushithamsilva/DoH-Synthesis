{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Loading Dataset...\n",
      "Training Websites: [1309, 228, 51, 563, 501, 457, 285, 209, 1385, 1116, 178, 1209, 864, 65, 61, 191, 447, 476, 1034, 1232, 54, 1149, 407, 1466, 1330, 1436, 1490, 859, 451, 919, 1206, 569, 13, 326, 1429, 865, 696, 1468, 318, 440, 689, 1492, 189, 778, 198, 735, 704, 1236, 541, 88, 940, 1098, 255, 775, 161, 1130, 600, 1287, 1266, 740, 1182, 393, 142, 93, 1354, 466, 592, 163, 1482, 206, 1456, 1462, 928, 1301, 747, 333, 758, 727, 429, 1372, 546, 1399, 1327, 146, 1247, 1300, 350, 1093, 1495, 334, 946, 777, 552, 1310, 1140, 449, 1402, 664, 114, 469, 1486, 646, 821, 548, 135, 432, 1161, 644, 435, 1342, 1022, 810, 1316, 939, 292, 542, 1493, 505, 1478, 1103, 538, 1197, 877, 1195, 817, 741, 1404, 283, 1043, 1010, 186, 96, 224, 313, 1285, 327, 1487, 1221, 130, 788, 781, 1220, 958, 1083, 514, 1133, 23, 234, 1099, 1419, 1312, 1463, 1498, 601, 890, 323, 929, 6, 539, 1025, 365, 1039, 217, 1280, 611, 1308, 1338, 1415, 1477, 1366, 765, 330, 1104, 1086, 1, 1226, 663, 1000, 39, 229, 743, 629, 490, 118, 493, 1393, 1445, 175, 995, 141, 1090, 257, 262, 973, 1125, 338, 1384, 1080, 1242, 866, 433, 1417, 411, 638, 1375, 764, 897, 1059, 924, 247, 507, 460, 131, 692, 43, 1204, 1134, 471, 1205, 1471, 14, 145, 120, 468, 138, 64, 676, 1278, 1052, 487, 570, 994, 438, 1298, 270, 1169, 1180, 968, 497, 1262, 833, 389, 193, 1455, 882, 725, 867, 841, 956, 110, 201, 124, 824, 694, 223, 509, 392, 1258, 1448, 918, 287, 1363, 375, 1269, 947, 511, 154, 907, 1127, 200, 103, 1107, 30, 1484, 484, 340, 832, 1268, 985, 437, 1397, 1277, 337, 776, 4, 799, 543, 931, 584, 1414, 1138, 996, 317, 388, 607, 445, 119, 1186, 1110, 1248, 642, 117, 102, 1196, 976, 1029, 1087, 322, 116, 1040, 164, 380, 140, 139, 481, 826, 245, 1166, 504, 81, 167, 858, 1157, 1070, 647, 534, 418, 643, 488, 1213, 1388, 268, 614, 936, 1175, 148, 19, 938, 1153, 204, 150, 1101, 436, 1036, 1170, 271, 714, 1187, 500, 756, 583, 1344, 1293, 1112, 619, 1356, 16, 1135, 613, 212, 275, 1451, 236, 219, 1435, 1461, 557, 577, 431, 702, 416, 540, 1035, 1322, 1355, 104, 1457, 1253, 566, 90, 7, 683, 267, 536, 1328, 904, 875, 1163, 1320, 1233, 305, 73, 1150, 303, 880, 261, 85, 631, 746, 1263, 732, 430, 1234, 210, 724, 1223, 316, 1225, 332, 362, 844, 50, 367, 680, 843, 508, 1350, 1476, 221, 783, 79, 963, 455, 408, 942, 716, 625, 1434, 456, 48, 395, 816, 672, 1452, 1437, 571, 719, 1371, 818, 678, 56, 1137, 1174, 1339, 1155, 78, 222, 889, 707, 1199, 893, 1047, 1058, 1360, 1426, 521, 1120, 1049, 3, 403, 745, 883, 143, 1273, 1050, 1447, 615, 633, 836, 668, 1332, 605, 260, 1243, 861, 1216, 356, 630, 582, 308, 415, 561, 853, 0, 311, 293, 215, 1460, 804, 593, 621, 670, 329, 1431, 452, 1005, 691, 218, 523, 1092, 812, 922, 982, 815, 753, 173, 674, 86, 290, 527, 679, 648, 634, 343, 95, 838, 974, 769, 240, 688, 1207, 230, 825, 203, 1159, 25, 47, 250, 486, 1073, 870, 786, 74, 1072, 424, 1480, 1392, 589, 199, 1454, 713, 1438, 506, 409, 249, 151, 671, 1453, 5, 914, 768, 881, 1046, 906, 109, 797, 1391, 1367, 180, 823, 712, 530, 475, 1497, 1066, 1481, 868, 1200, 467, 136, 820, 937, 1118, 1055, 572, 609, 324, 773, 912, 453, 627, 834, 736, 913, 516, 1177, 850, 1018, 1071, 162, 761, 1255, 971, 1288, 265, 997, 253, 860, 652, 1420, 784, 796, 533, 496, 641, 244, 281, 450, 1079, 730, 1491, 981, 278, 986, 1364, 553, 82, 1406, 1201, 1048, 1026, 710, 156, 723, 1136, 1418, 965, 417, 1304, 555, 477, 425, 63, 211, 852, 1241, 398, 1235, 598, 1386, 20, 1302, 962, 1045, 1171, 1390, 360, 1109, 771, 399, 1421, 551, 1329, 752, 559, 819, 617, 225, 499, 1075, 279, 446, 1261, 29, 863, 344, 684, 695, 1295, 414, 1374, 169, 478, 1361, 637, 1144, 27, 1190, 606, 1132, 1060, 1449, 1380, 658, 1267, 1275, 472, 1369, 1439, 266, 1469, 335, 216, 465, 1410, 345, 779, 809, 284, 770, 1131, 258, 83, 1185, 1146, 767, 1407, 53, 358, 1111, 665, 70, 667, 41, 772, 31, 903, 1160, 1472, 636, 1377, 894, 129, 1126, 685, 1198, 1343, 1245, 1006, 1074, 1307, 377, 171, 620, 1009, 960, 774, 1179, 1283, 1250, 1433, 26, 319, 857, 693, 384, 406, 1351, 1376, 77, 1219, 1051, 1231, 248, 1124, 959, 1020, 700, 1167, 123, 579, 42, 355, 545, 1208, 677, 379, 862, 518, 1323, 349, 12, 1238, 1411, 108, 443, 370, 650, 470, 803, 1284, 941, 1057, 666, 276, 1389, 848, 495, 851, 984, 749, 274, 1115, 251, 1450, 1383, 461, 955, 1427, 1381, 624, 1259, 802, 1240, 1031, 957, 1091, 999, 1252, 1337, 363, 264, 348, 286, 610, 282, 1428, 10, 529, 195, 87, 1290, 1129, 1151, 568, 246, 1270, 661, 502, 458, 17, 1362, 301, 226, 830, 1444, 1475, 595, 949, 1024, 1121, 926, 352, 943, 1496, 871, 1017, 464, 277, 1345, 1334, 1105, 1440, 197, 1148, 122, 1396, 1123, 196, 1081, 902, 900, 603, 537, 1335, 289, 1378, 1256, 1106, 232, 369, 183, 309, 1279, 1194, 1408, 280, 46, 55, 659, 299, 699, 953, 105, 728, 587, 291, 480, 1317, 1336, 687, 188, 52, 798, 489, 1191, 66, 410, 503, 75, 590, 1479, 155, 152, 576, 1015, 989, 254, 121, 1064, 426, 231, 535, 856, 703, 920, 304, 439, 312, 1485, 101, 1405, 807, 1265, 944, 160, 1183, 177, 565, 76, 574, 2, 1173, 585, 898, 298, 33, 237, 295, 987, 901, 72, 239, 662, 202, 656, 763, 978, 596, 272, 1272, 1108, 580, 828, 314, 921, 1373, 127, 479, 594, 412, 887, 512, 1382, 448, 1038, 40, 442, 748, 256, 1423, 1474, 1352, 21, 1139, 1260, 179, 599, 1004, 801, 185, 878, 1346, 528, 522, 1023, 567, 341, 328, 886, 792, 1021, 717, 168, 1096, 737, 1178, 147, 339, 483, 205, 734, 586, 1042, 18, 1314, 45, 1313, 618, 165, 59, 1069, 1430, 532, 263, 422, 1016, 336, 1063, 651, 988, 1210, 1061, 1368, 905, 519, 909, 387, 934, 320, 800, 837, 681, 1333, 930, 896, 67, 1085, 840, 892, 357, 1158, 62, 626, 1192, 1128, 1251, 1078, 1459, 1100, 159, 698, 1119, 829, 208, 1306, 115, 1422, 58, 1488, 60, 331, 1228, 1054, 1282, 366, 149, 1027, 361, 1202, 578, 427, 1089, 241, 932, 233, 731, 967, 895, 97, 306, 1394, 382, 69, 35, 908, 855, 404, 849, 174, 822, 259, 806, 1325, 144, 371, 744, 300, 296, 1217, 972, 935, 1347, 525, 428, 176, 170, 423, 390, 1379, 1257, 873, 1189, 711, 459, 1044, 1271, 421, 1203, 1473, 22, 910, 242, 1214, 1326, 1398, 726, 1424, 750, 517, 639, 1274, 649, 302, 970, 811, 842, 364, 269, 697, 1483, 1172, 1458, 808, 891, 38, 888, 1395, 1222, 757, 751, 755, 524, 1246, 1011, 273, 194, 378, 721, 1403, 612, 1318, 1412, 1019, 1218, 645, 462, 604, 622, 1053, 1088, 923, 1499, 227, 831, 153, 911, 1353, 166, 28, 975, 628, 1324, 220, 660, 125, 1154, 1188, 560, 92, 1370, 89, 1147, 1237, 1165, 759, 564, 791, 1387, 1012]\n",
      "Training Locations: ['LOC2', 'LOC3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asil0892/doh_traffic_analysis/code/scripts/init_dataset.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.sort_values(by=[\"Location\"], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Website</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.714089</td>\n",
       "      <td>0.541197</td>\n",
       "      <td>0.391921</td>\n",
       "      <td>-0.400778</td>\n",
       "      <td>-0.266345</td>\n",
       "      <td>-0.522526</td>\n",
       "      <td>0.023889</td>\n",
       "      <td>-0.261817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.093792</td>\n",
       "      <td>-1.273349</td>\n",
       "      <td>-2.142801</td>\n",
       "      <td>1.205098</td>\n",
       "      <td>1.879002</td>\n",
       "      <td>2.139593</td>\n",
       "      <td>1.482513</td>\n",
       "      <td>2.382939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>1.401091</td>\n",
       "      <td>-1.636258</td>\n",
       "      <td>0.527106</td>\n",
       "      <td>0.354928</td>\n",
       "      <td>-0.017609</td>\n",
       "      <td>-0.049260</td>\n",
       "      <td>-0.177300</td>\n",
       "      <td>-0.412692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>-0.831599</td>\n",
       "      <td>0.662167</td>\n",
       "      <td>0.527106</td>\n",
       "      <td>0.354928</td>\n",
       "      <td>-0.017609</td>\n",
       "      <td>-0.049260</td>\n",
       "      <td>-0.177300</td>\n",
       "      <td>-0.412692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.093792</td>\n",
       "      <td>-1.152379</td>\n",
       "      <td>-2.007616</td>\n",
       "      <td>0.827245</td>\n",
       "      <td>1.630266</td>\n",
       "      <td>1.666328</td>\n",
       "      <td>1.281324</td>\n",
       "      <td>2.311938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location  Website         0         1         2         3         4  \\\n",
       "0     LOC2        0 -0.714089  0.541197  0.391921 -0.400778 -0.266345   \n",
       "1     LOC2     1006  0.093792 -1.273349 -2.142801  1.205098  1.879002   \n",
       "2     LOC2     1006  1.401091 -1.636258  0.527106  0.354928 -0.017609   \n",
       "3     LOC2     1006 -0.831599  0.662167  0.527106  0.354928 -0.017609   \n",
       "4     LOC2     1006  0.093792 -1.152379 -2.007616  0.827245  1.630266   \n",
       "\n",
       "          5         6         7  ...       118      119       120       121  \\\n",
       "0 -0.522526  0.023889 -0.261817  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "1  2.139593  1.482513  2.382939  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "2 -0.049260 -0.177300 -0.412692  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "3 -0.049260 -0.177300 -0.412692  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "4  1.666328  1.281324  2.311938  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "\n",
       "        122       123       124       125       126       127  \n",
       "0  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "1  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "2  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "3  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "4  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scripts.init_gpu as init_gpu\n",
    "import scripts.init_dataset as init_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "init_gpu.initialize_gpus()\n",
    "\n",
    "locations = ['LOC2', 'LOC3']\n",
    "\n",
    "print(\"Loading Dataset...\")\n",
    "# load the dataset\n",
    "df = pd.read_csv(\n",
    "    f\"../dataset/processed/{locations[0]}-{locations[1]}-scaled-balanced.csv\")\n",
    "\n",
    "length = len(df.columns) - 2  # subtract the two label columns\n",
    "\n",
    "# get train-test set\n",
    "train_df, test_df, train_web_sam1ples, test_web_samples = init_dataset.get_sample(\n",
    "    df, locations, range(1500), 1200)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asil0892/doh_traffic_analysis/.venv/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1733291557.363866  515107 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1733291557.363960  515107 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21242 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:71:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from scripts.train_vae import VAE, Sampling, ConvVAE_BatchNorm\n",
    "import tensorflow as tf\n",
    "# web_model = tf.keras.models.load_model(f\"../models/website/{locations[0]}-{locations[1]}-baseGRU-epochs300-train_samples1200-triplet_samples5.keras\")\n",
    "\n",
    "# location = 'LOC1'\n",
    "vae_model = tf.keras.models.load_model(f\"../models-{locations[0]}-{locations[1]}/vae/ci_vae/ConvBased/domain_and_class/{locations[0]}-{locations[1]}-e800-mse1-kl1.0-cl1.0-ConvBatchNorm-ldim96-hdim128.keras\", custom_objects={'ConvVAE_BatchNorm': ConvVAE_BatchNorm, 'Sampling': Sampling})\n",
    "\n",
    "def get_latent_z(x):\n",
    "    content_tensor = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "    z_mean, z_log_var, z = vae_model.encode(content_tensor)\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def preprocess_data(train_df: pd.DataFrame, test_df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, LabelEncoder]:\n",
    "    le = LabelEncoder()\n",
    "\n",
    "\n",
    "    X_train = train_df.iloc[:, 2:].to_numpy().astype(np.float32)\n",
    "    X_test = test_df.iloc[:, 2:].to_numpy().astype(np.float32)\n",
    "\n",
    "    y_train = le.fit_transform(train_df['Location'])\n",
    "    y_test = le.transform(test_df['Location'])\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test, le)\n",
    "\n",
    "X_train, X_test, y_train, y_test, le = preprocess_data(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trace Location Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.90, F1 Score:  98.90, Precision:  98.90, Recall:  98.90\n",
      "Accuracy: 98.90, Precision: 98.90, Recall: 98.90, F1: 98.90\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.classification import evaluate_classification_model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = XGBClassifier()\n",
    "accuracy, precision, recall,f1_score,  confusion_matrix = evaluate_classification_model(X_train, y_train, X_test, y_test, model)\n",
    "print(f\"Accuracy: {accuracy * 100.0:.2f}, Precision: {precision * 100.0:.2f}, Recall: {recall * 100.0:.2f}, F1: {f1_score * 100 :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# latent location classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z_embeddings(data, vae_model=vae_model):\n",
    "    embeddings = []\n",
    "    chunk_size = 200\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        chunk = data[i:i+chunk_size]\n",
    "        _, _, transformed_chunk = vae_model.encode(chunk)\n",
    "        embeddings.append(transformed_chunk)\n",
    "\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733291566.212829  515252 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    }
   ],
   "source": [
    "X_train_latent = get_z_embeddings(X_train)\n",
    "X_test_latent = get_z_embeddings(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Location Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.53, F1 Score:  92.53, Precision:  92.53, Recall:  92.53\n",
      "Accuracy: 92.53, Precision: 92.53, Recall: 92.53, F1: 92.53\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.classification import evaluate_classification_model\n",
    "\n",
    "\n",
    "model = XGBClassifier()\n",
    "accuracy, precision, recall,f1_score,  confusion_matrix = evaluate_classification_model(X_train_latent, y_train, X_test_latent, y_test, model)\n",
    "print(f\"Accuracy: {accuracy * 100.0:.2f}, Precision: {precision * 100.0:.2f}, Recall: {recall * 100.0:.2f}, F1: {f1_score * 100 :.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00405046 0.00304441 0.01063453 0.00269815 0.00891247 0.00292919\n",
      " 0.00247125 0.0025562  0.06661493 0.00582328 0.01358247 0.00313984\n",
      " 0.007664   0.01386086 0.00671635 0.00411503 0.01389668 0.0181261\n",
      " 0.00320654 0.00609518 0.02637232 0.00269016 0.00331527 0.09723118\n",
      " 0.09790697 0.00458108 0.00381496 0.00218996 0.00588743 0.00997487\n",
      " 0.0041265  0.00651746 0.00262523 0.00241399 0.00372101 0.00474037\n",
      " 0.00243154 0.00159811 0.03065409 0.00293524 0.00269763 0.06304755\n",
      " 0.00334119 0.00256522 0.01039221 0.00217019 0.00246243 0.0032072\n",
      " 0.00237414 0.00529339 0.00992261 0.00590507 0.05557018 0.00779107\n",
      " 0.00251709 0.00416622 0.03713388 0.00239316 0.02231717 0.00264888\n",
      " 0.00245257 0.0028843  0.00282786 0.0021409  0.00231069 0.00385858\n",
      " 0.00325019 0.00262873 0.00290775 0.00263095 0.00398819 0.00228586\n",
      " 0.00231377 0.00327847 0.00459211 0.00793476 0.00561628 0.00262848\n",
      " 0.00698132 0.00892262 0.00255941 0.00296923 0.0090694  0.00206496\n",
      " 0.00306212 0.00247239 0.00427706 0.00324003 0.00492731 0.07178298\n",
      " 0.00266608 0.00298419 0.02237548 0.00281008 0.01986593 0.00265675]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# feature importance\n",
    "print(model.feature_importances_)\n",
    "# plot\n",
    "plt.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asil0892/doh_traffic_analysis/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733291648.015977  515250 service.cc:148] XLA service 0x7fc1444503a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733291648.015996  515250 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-12-04 16:54:08.041658: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-04 16:54:08.427928: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version 12.5.82. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "I0000 00:00:1733291648.605458  515250 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6683/6683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.7169 - loss: 0.5473 - val_accuracy: 0.8385 - val_loss: 0.3405\n",
      "Epoch 2/10\n",
      "\u001b[1m6683/6683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.3293 - val_accuracy: 0.8902 - val_loss: 0.2495\n",
      "Epoch 3/10\n",
      "\u001b[1m6683/6683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.2850 - val_accuracy: 0.8961 - val_loss: 0.2348\n",
      "Epoch 4/10\n",
      "\u001b[1m6683/6683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.2693 - val_accuracy: 0.9017 - val_loss: 0.2297\n",
      "Epoch 5/10\n",
      "\u001b[1m6683/6683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.2597 - val_accuracy: 0.9034 - val_loss: 0.2220\n",
      "Epoch 6/10\n",
      "\u001b[1m6683/6683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.2486 - val_accuracy: 0.9058 - val_loss: 0.2195\n",
      "Epoch 7/10\n",
      "\u001b[1m6683/6683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2403 - val_accuracy: 0.8721 - val_loss: 0.2866\n",
      "Epoch 8/10\n",
      "\u001b[1m6683/6683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9037 - loss: 0.2377 - val_accuracy: 0.8816 - val_loss: 0.2815\n",
      "Epoch 9/10\n",
      "\u001b[1m6683/6683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9060 - loss: 0.2330 - val_accuracy: 0.9051 - val_loss: 0.2306\n",
      "Epoch 10/10\n",
      "\u001b[1m6683/6683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2271 - val_accuracy: 0.9048 - val_loss: 0.2350\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU, RepeatVector\n",
    "from scripts.classification import evaluate_classification_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a simple feedforward neural network model for binary classification\n",
    "def build_neural_network(input_dim):\n",
    "    model = Sequential([\n",
    "        # RepeatVector(1),\n",
    "        # GRU(32, recurrent_dropout=0.1),\n",
    "        \n",
    "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Set input dimension\n",
    "input_dim = X_train_latent.shape[1]\n",
    "\n",
    "# Initialize the model\n",
    "model = build_neural_network(input_dim)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_latent, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "model.save(\"../models-LOC2-LOC3/classification/location/latent_ci_vae-e800-kl1.0.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306us/step\n",
      "Accuracy: 92.04, F1: 91.92 Precision: 93.35, Recall: 90.53\n",
      "Accuracy: 92.04, F1: 91.92 Precision: 93.35, Recall: 90.53\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_classification_neural_model(X_test, y_test, model):\n",
    "    # Generate predictions on the test set\n",
    "    y_pred_prob = model.predict(X_test)  # Predicted probabilities\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy * 100.0:.2f}, F1: {f1 * 100:.2f} Precision: {precision * 100.0:.2f}, Recall: {recall * 100.0:.2f}\")\n",
    "    return accuracy, precision, recall, f1, conf_matrix\n",
    "\n",
    "accuracy, precision, recall, f1_score, confusion_matrix = evaluate_classification_neural_model(X_test_latent, y_test, model)\n",
    "print(f\"Accuracy: {accuracy * 100.0:.2f}, F1: {f1_score * 100:.2f} Precision: {precision * 100.0:.2f}, Recall: {recall * 100.0:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Location Classification: To find a hyperplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.35, F1 Score:  71.35, Precision:  71.35, Recall:  71.35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7134680134680135,\n",
       " 0.7135033332884477,\n",
       " 0.7134680134680135,\n",
       " 0.7134561627433402,\n",
       " array([[21381,  8319],\n",
       "        [ 8701, 20999]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from scripts.classification import evaluate_classification_model\n",
    "\n",
    "model = svm.LinearSVC()\n",
    "evaluate_classification_model(X_train_latent, y_train, X_test_latent, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00397081, -0.01352405, -0.09995704, -0.04965017,  0.0385788 ,\n",
       "         -0.03083002,  0.03959346,  0.00956229,  0.00140596, -0.03013246,\n",
       "         -0.01612792, -0.06630699, -0.07444691,  0.01047472, -0.00322296,\n",
       "         -0.04055877, -0.00997551, -0.01367152, -0.01247419,  0.01672801,\n",
       "          0.04173102,  0.01142011,  0.01137553, -0.02385601, -0.09071965,\n",
       "          0.05246061,  0.02174831,  0.01471895,  0.01721549,  0.02575407,\n",
       "          0.06012632,  0.0020044 ,  0.02336756, -0.04329318,  0.04956333,\n",
       "         -0.05855261, -0.02199754,  0.02927844, -0.01261431, -0.01241895,\n",
       "         -0.0230875 , -0.06681904,  0.05003476,  0.02010518,  0.00346181,\n",
       "          0.02301707, -0.0304388 ,  0.02017233, -0.02029821,  0.00345141,\n",
       "          0.06968749, -0.00651222,  0.01388922, -0.07017124, -0.02261628,\n",
       "         -0.02848751, -0.00235629,  0.08148276,  0.01940355, -0.05463024,\n",
       "         -0.04234615,  0.02737515,  0.00801456,  0.00943895,  0.03832499,\n",
       "         -0.01716799,  0.01079273, -0.01986633,  0.03159492, -0.00258454,\n",
       "         -0.01031847, -0.07925162,  0.00626852, -0.02589095, -0.00395344,\n",
       "         -0.06904251, -0.01758507,  0.01719869, -0.02909967, -0.03388537,\n",
       "         -0.04122025, -0.00098614,  0.01486403,  0.04266671,  0.042337  ,\n",
       "         -0.01553584, -0.00501366,  0.01316141,  0.17782364, -0.01805652,\n",
       "          0.02950194,  0.04658735,  0.04164909,  0.01599433,  0.07233132,\n",
       "         -0.00649469]]),\n",
       " array([0.67544161]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.coef_\n",
    "bias = model.intercept_\n",
    "\n",
    "weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location Classification within Triplet Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731544262.527723 3382693 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "web_model = tf.keras.models.load_model(f\"../models/website/LOC1-LOC2-baseGRU-epochs200-train_samples1200-triplet_samples5.keras\")\n",
    "\n",
    "def get_web_embeddings(data, web_model):\n",
    "    embeddings = []\n",
    "    chunk_size = 2000\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        chunk = data[i: i + chunk_size]\n",
    "        \n",
    "        # Pad the chunk if it's smaller than chunk_size\n",
    "        if len(chunk) < chunk_size:\n",
    "            chunk = chunk.reindex(range(chunk_size), fill_value=0)\n",
    "        \n",
    "        transformed_chunk = web_model(chunk)\n",
    "        embeddings.append(transformed_chunk)\n",
    "    \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "X_train_triplet = get_web_embeddings(X_train, web_model)\n",
    "X_test_triplet = get_web_embeddings(X_test, web_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.21, F1 Score:  89.18, Precision:  89.72, Recall:  89.21\n",
      "Accuracy: 89.21, Precision: 89.72, Recall: 89.21, F1: 89.18\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.classification import evaluate_classification_model\n",
    "\n",
    "\n",
    "model = XGBClassifier()\n",
    "accuracy, precision, recall,f1_score,  confusion_matrix = evaluate_classification_model(X_train_triplet, y_train, X_test_triplet, y_test, model)\n",
    "print(f\"Accuracy: {accuracy * 100.0:.2f}, Precision: {precision * 100.0:.2f}, Recall: {recall * 100.0:.2f}, F1: {f1_score * 100 :.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asil0892/doh_traffic_analysis/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731333460.909584 3072061 service.cc:148] XLA service 0x7f578459dd50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731333460.909701 3072061 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "I0000 00:00:1731333460.909705 3072061 service.cc:156]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-11-12 00:57:40.941938: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-12 00:57:41.335500: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version 12.5.82. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "I0000 00:00:1731333461.524975 3072061 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13500/13500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 336us/step - accuracy: 0.5724 - loss: 0.6722 - val_accuracy: 0.4232 - val_loss: 0.9543\n",
      "Epoch 2/10\n",
      "\u001b[1m13500/13500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 313us/step - accuracy: 0.6619 - loss: 0.6009 - val_accuracy: 0.4526 - val_loss: 1.0049\n",
      "Epoch 3/10\n",
      "\u001b[1m13500/13500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 324us/step - accuracy: 0.6943 - loss: 0.5670 - val_accuracy: 0.4728 - val_loss: 1.0447\n",
      "Epoch 4/10\n",
      "\u001b[1m13500/13500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 453us/step - accuracy: 0.7105 - loss: 0.5482 - val_accuracy: 0.5065 - val_loss: 1.0412\n",
      "Epoch 5/10\n",
      "\u001b[1m13500/13500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 421us/step - accuracy: 0.7204 - loss: 0.5343 - val_accuracy: 0.5240 - val_loss: 1.0106\n",
      "Epoch 6/10\n",
      "\u001b[1m13500/13500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 362us/step - accuracy: 0.7268 - loss: 0.5263 - val_accuracy: 0.5091 - val_loss: 1.0482\n",
      "Epoch 7/10\n",
      "\u001b[1m13500/13500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 320us/step - accuracy: 0.7332 - loss: 0.5190 - val_accuracy: 0.5496 - val_loss: 0.9851\n",
      "Epoch 8/10\n",
      "\u001b[1m13500/13500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 404us/step - accuracy: 0.7384 - loss: 0.5126 - val_accuracy: 0.5247 - val_loss: 1.0583\n",
      "Epoch 9/10\n",
      "\u001b[1m13500/13500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 355us/step - accuracy: 0.7422 - loss: 0.5053 - val_accuracy: 0.5383 - val_loss: 1.0353\n",
      "Epoch 10/10\n",
      "\u001b[1m13500/13500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 357us/step - accuracy: 0.7453 - loss: 0.5020 - val_accuracy: 0.5192 - val_loss: 1.0767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f5794032c20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU, RepeatVector\n",
    "from scripts.classification import evaluate_classification_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a simple feedforward neural network model for binary classification\n",
    "def build_neural_network(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Set input dimension\n",
    "input_dim = X_train_triplet.shape[1]\n",
    "\n",
    "# Initialize the model\n",
    "model = build_neural_network(input_dim)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_triplet, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "# model.save(\"../models/classification/location/triplet_classifier.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290us/step\n",
      "Accuracy: 66.38, F1: 67.04 Precision: 65.74, Recall: 68.40\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.load_model(\"../models/classification/location/triplet_classifier.keras\")\n",
    "accuracy, precision, recall, f1_score, confusion_matrix = evaluate_classification_neural_model(X_test_triplet, y_test, model)\n",
    "print(f\"Accuracy: {accuracy * 100.0:.2f}, F1: {f1_score * 100:.2f} Precision: {precision * 100.0:.2f}, Recall: {recall * 100.0:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
