{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the translated z latent embeddings\n",
    "Due to the architecture of the CI-DI-VAE, we can expect a simple classifier to classify the latent embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 00:51:33.043643: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-23 00:51:33.059221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737573693.067754  230991 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737573693.071439  230991 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-23 00:51:33.087029: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Loading Dataset...\n",
      "Training Websites: [1309, 228, 51, 563, 501, 457, 285, 209, 1385, 1116, 178, 1209, 864, 65, 61, 191, 447, 476, 1034, 1232, 54, 1149, 407, 1466, 1330, 1436, 1490, 859, 451, 919, 1206, 569, 13, 326, 1429, 865, 696, 1468, 318, 440, 689, 1492, 189, 778, 198, 735, 704, 1236, 541, 88, 940, 1098, 255, 775, 161, 1130, 600, 1287, 1266, 740, 1182, 393, 142, 93, 1354, 466, 592, 163, 1482, 206, 1456, 1462, 928, 1301, 747, 333, 758, 727, 429, 1372, 546, 1399, 1327, 146, 1247, 1300, 350, 1093, 1495, 334, 946, 777, 552, 1310, 1140, 449, 1402, 664, 114, 469, 1486, 646, 821, 548, 135, 432, 1161, 644, 435, 1342, 1022, 810, 1316, 939, 292, 542, 1493, 505, 1478, 1103, 538, 1197, 877, 1195, 817, 741, 1404, 283, 1043, 1010, 186, 96, 224, 313, 1285, 327, 1487, 1221, 130, 788, 781, 1220, 958, 1083, 514, 1133, 23, 234, 1099, 1419, 1312, 1463, 1498, 601, 890, 323, 929, 6, 539, 1025, 365, 1039, 217, 1280, 611, 1308, 1338, 1415, 1477, 1366, 765, 330, 1104, 1086, 1, 1226, 663, 1000, 39, 229, 743, 629, 490, 118, 493, 1393, 1445, 175, 995, 141, 1090, 257, 262, 973, 1125, 338, 1384, 1080, 1242, 866, 433, 1417, 411, 638, 1375, 764, 897, 1059, 924, 247, 507, 460, 131, 692, 43, 1204, 1134, 471, 1205, 1471, 14, 145, 120, 468, 138, 64, 676, 1278, 1052, 487, 570, 994, 438, 1298, 270, 1169, 1180, 968, 497, 1262, 833, 389, 193, 1455, 882, 725, 867, 841, 956, 110, 201, 124, 824, 694, 223, 509, 392, 1258, 1448, 918, 287, 1363, 375, 1269, 947, 511, 154, 907, 1127, 200, 103, 1107, 30, 1484, 484, 340, 832, 1268, 985, 437, 1397, 1277, 337, 776, 4, 799, 543, 931, 584, 1414, 1138, 996, 317, 388, 607, 445, 119, 1186, 1110, 1248, 642, 117, 102, 1196, 976, 1029, 1087, 322, 116, 1040, 164, 380, 140, 139, 481, 826, 245, 1166, 504, 81, 167, 858, 1157, 1070, 647, 534, 418, 643, 488, 1213, 1388, 268, 614, 936, 1175, 148, 19, 938, 1153, 204, 150, 1101, 436, 1036, 1170, 271, 714, 1187, 500, 756, 583, 1344, 1293, 1112, 619, 1356, 16, 1135, 613, 212, 275, 1451, 236, 219, 1435, 1461, 557, 577, 431, 702, 416, 540, 1035, 1322, 1355, 104, 1457, 1253, 566, 90, 7, 683, 267, 536, 1328, 904, 875, 1163, 1320, 1233, 305, 73, 1150, 303, 880, 261, 85, 631, 746, 1263, 732, 430, 1234, 210, 724, 1223, 316, 1225, 332, 362, 844, 50, 367, 680, 843, 508, 1350, 1476, 221, 783, 79, 963, 455, 408, 942, 716, 625, 1434, 456, 48, 395, 816, 672, 1452, 1437, 571, 719, 1371, 818, 678, 56, 1137, 1174, 1339, 1155, 78, 222, 889, 707, 1199, 893, 1047, 1058, 1360, 1426, 521, 1120, 1049, 3, 403, 745, 883, 143, 1273, 1050, 1447, 615, 633, 836, 668, 1332, 605, 260, 1243, 861, 1216, 356, 630, 582, 308, 415, 561, 853, 0, 311, 293, 215, 1460, 804, 593, 621, 670, 329, 1431, 452, 1005, 691, 218, 523, 1092, 812, 922, 982, 815, 753, 173, 674, 86, 290, 527, 679, 648, 634, 343, 95, 838, 974, 769, 240, 688, 1207, 230, 825, 203, 1159, 25, 47, 250, 486, 1073, 870, 786, 74, 1072, 424, 1480, 1392, 589, 199, 1454, 713, 1438, 506, 409, 249, 151, 671, 1453, 5, 914, 768, 881, 1046, 906, 109, 797, 1391, 1367, 180, 823, 712, 530, 475, 1497, 1066, 1481, 868, 1200, 467, 136, 820, 937, 1118, 1055, 572, 609, 324, 773, 912, 453, 627, 834, 736, 913, 516, 1177, 850, 1018, 1071, 162, 761, 1255, 971, 1288, 265, 997, 253, 860, 652, 1420, 784, 796, 533, 496, 641, 244, 281, 450, 1079, 730, 1491, 981, 278, 986, 1364, 553, 82, 1406, 1201, 1048, 1026, 710, 156, 723, 1136, 1418, 965, 417, 1304, 555, 477, 425, 63, 211, 852, 1241, 398, 1235, 598, 1386, 20, 1302, 962, 1045, 1171, 1390, 360, 1109, 771, 399, 1421, 551, 1329, 752, 559, 819, 617, 225, 499, 1075, 279, 446, 1261, 29, 863, 344, 684, 695, 1295, 414, 1374, 169, 478, 1361, 637, 1144, 27, 1190, 606, 1132, 1060, 1449, 1380, 658, 1267, 1275, 472, 1369, 1439, 266, 1469, 335, 216, 465, 1410, 345, 779, 809, 284, 770, 1131, 258, 83, 1185, 1146, 767, 1407, 53, 358, 1111, 665, 70, 667, 41, 772, 31, 903, 1160, 1472, 636, 1377, 894, 129, 1126, 685, 1198, 1343, 1245, 1006, 1074, 1307, 377, 171, 620, 1009, 960, 774, 1179, 1283, 1250, 1433, 26, 319, 857, 693, 384, 406, 1351, 1376, 77, 1219, 1051, 1231, 248, 1124, 959, 1020, 700, 1167, 123, 579, 42, 355, 545, 1208, 677, 379, 862, 518, 1323, 349, 12, 1238, 1411, 108, 443, 370, 650, 470, 803, 1284, 941, 1057, 666, 276, 1389, 848, 495, 851, 984, 749, 274, 1115, 251, 1450, 1383, 461, 955, 1427, 1381, 624, 1259, 802, 1240, 1031, 957, 1091, 999, 1252, 1337, 363, 264, 348, 286, 610, 282, 1428, 10, 529, 195, 87, 1290, 1129, 1151, 568, 246, 1270, 661, 502, 458, 17, 1362, 301, 226, 830, 1444, 1475, 595, 949, 1024, 1121, 926, 352, 943, 1496, 871, 1017, 464, 277, 1345, 1334, 1105, 1440, 197, 1148, 122, 1396, 1123, 196, 1081, 902, 900, 603, 537, 1335, 289, 1378, 1256, 1106, 232, 369, 183, 309, 1279, 1194, 1408, 280, 46, 55, 659, 299, 699, 953, 105, 728, 587, 291, 480, 1317, 1336, 687, 188, 52, 798, 489, 1191, 66, 410, 503, 75, 590, 1479, 155, 152, 576, 1015, 989, 254, 121, 1064, 426, 231, 535, 856, 703, 920, 304, 439, 312, 1485, 101, 1405, 807, 1265, 944, 160, 1183, 177, 565, 76, 574, 2, 1173, 585, 898, 298, 33, 237, 295, 987, 901, 72, 239, 662, 202, 656, 763, 978, 596, 272, 1272, 1108, 580, 828, 314, 921, 1373, 127, 479, 594, 412, 887, 512, 1382, 448, 1038, 40, 442, 748, 256, 1423, 1474, 1352, 21, 1139, 1260, 179, 599, 1004, 801, 185, 878, 1346, 528, 522, 1023, 567, 341, 328, 886, 792, 1021, 717, 168, 1096, 737, 1178, 147, 339, 483, 205, 734, 586, 1042, 18, 1314, 45, 1313, 618, 165, 59, 1069, 1430, 532, 263, 422, 1016, 336, 1063, 651, 988, 1210, 1061, 1368, 905, 519, 909, 387, 934, 320, 800, 837, 681, 1333, 930, 896, 67, 1085, 840, 892, 357, 1158, 62, 626, 1192, 1128, 1251, 1078, 1459, 1100, 159, 698, 1119, 829, 208, 1306, 115, 1422, 58, 1488, 60, 331, 1228, 1054, 1282, 366, 149, 1027, 361, 1202, 578, 427, 1089, 241, 932, 233, 731, 967, 895, 97, 306, 1394, 382, 69, 35, 908, 855, 404, 849, 174, 822, 259, 806, 1325, 144, 371, 744, 300, 296, 1217, 972, 935, 1347, 525, 428, 176, 170, 423, 390, 1379, 1257, 873, 1189, 711, 459, 1044, 1271, 421, 1203, 1473, 22, 910, 242, 1214, 1326, 1398, 726, 1424, 750, 517, 639, 1274, 649, 302, 970, 811, 842, 364, 269, 697, 1483, 1172, 1458, 808, 891, 38, 888, 1395, 1222, 757, 751, 755, 524, 1246, 1011, 273, 194, 378, 721, 1403, 612, 1318, 1412, 1019, 1218, 645, 462, 604, 622, 1053, 1088, 923, 1499, 227, 831, 153, 911, 1353, 166, 28, 975, 628, 1324, 220, 660, 125, 1154, 1188, 560, 92, 1370, 89, 1147, 1237, 1165, 759, 564, 791, 1387, 1012]\n",
      "Training Locations: ['LOC2', 'LOC3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e19372/DoH-Synthesis/code/scripts/init_dataset.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.sort_values(by=[\"Location\"], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Website</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.714089</td>\n",
       "      <td>0.541197</td>\n",
       "      <td>0.391921</td>\n",
       "      <td>-0.400778</td>\n",
       "      <td>-0.266345</td>\n",
       "      <td>-0.522526</td>\n",
       "      <td>0.023889</td>\n",
       "      <td>-0.261817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.093792</td>\n",
       "      <td>-1.273349</td>\n",
       "      <td>-2.142801</td>\n",
       "      <td>1.205098</td>\n",
       "      <td>1.879002</td>\n",
       "      <td>2.139593</td>\n",
       "      <td>1.482513</td>\n",
       "      <td>2.382939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>1.401091</td>\n",
       "      <td>-1.636258</td>\n",
       "      <td>0.527106</td>\n",
       "      <td>0.354928</td>\n",
       "      <td>-0.017609</td>\n",
       "      <td>-0.049260</td>\n",
       "      <td>-0.177300</td>\n",
       "      <td>-0.412692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>-0.831599</td>\n",
       "      <td>0.662167</td>\n",
       "      <td>0.527106</td>\n",
       "      <td>0.354928</td>\n",
       "      <td>-0.017609</td>\n",
       "      <td>-0.049260</td>\n",
       "      <td>-0.177300</td>\n",
       "      <td>-0.412692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.093792</td>\n",
       "      <td>-1.152379</td>\n",
       "      <td>-2.007616</td>\n",
       "      <td>0.827245</td>\n",
       "      <td>1.630266</td>\n",
       "      <td>1.666328</td>\n",
       "      <td>1.281324</td>\n",
       "      <td>2.311938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location  Website         0         1         2         3         4  \\\n",
       "0     LOC2        0 -0.714089  0.541197  0.391921 -0.400778 -0.266345   \n",
       "1     LOC2     1006  0.093792 -1.273349 -2.142801  1.205098  1.879002   \n",
       "2     LOC2     1006  1.401091 -1.636258  0.527106  0.354928 -0.017609   \n",
       "3     LOC2     1006 -0.831599  0.662167  0.527106  0.354928 -0.017609   \n",
       "4     LOC2     1006  0.093792 -1.152379 -2.007616  0.827245  1.630266   \n",
       "\n",
       "          5         6         7  ...       118      119       120       121  \\\n",
       "0 -0.522526  0.023889 -0.261817  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "1  2.139593  1.482513  2.382939  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "2 -0.049260 -0.177300 -0.412692  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "3 -0.049260 -0.177300 -0.412692  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "4  1.666328  1.281324  2.311938  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "\n",
       "        122       123       124       125       126       127  \n",
       "0  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "1  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "2  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "3  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "4  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scripts.init_gpu as init_gpu\n",
    "import scripts.init_dataset as init_dataset\n",
    "from scripts.triplet_functions import n_neurons\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "init_gpu.initialize_gpus()\n",
    "\n",
    "locations = ['LOC2', 'LOC3']\n",
    "\n",
    "print(\"Loading Dataset...\")\n",
    "# load the dataset\n",
    "df = pd.read_csv(\n",
    "    f\"../dataset/processed/{locations[0]}-{locations[1]}-scaled-balanced.csv\")\n",
    "\n",
    "length = len(df.columns) - 2  # subtract the two label columns\n",
    "\n",
    "# get train-test set\n",
    "train_df, test_df, train_web_samples, test_web_samples = init_dataset.get_sample(\n",
    "    df, locations, range(1500), 1200)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230991/955691792.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_df.sort_values(by=['Website'], inplace=True)\n",
      "/tmp/ipykernel_230991/955691792.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  source_df.sort_values(by=['Website'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    " # data preprocessing for source, real target, and synthetic data\n",
    "source_location, target_location = locations\n",
    "\n",
    "target_df = test_df[test_df['Location'] == target_location]\n",
    "target_df.sort_values(by=['Website'], inplace=True)\n",
    "target_df.reset_index(drop=True, inplace=True)\n",
    "target_df.head(20)\n",
    "\n",
    "source_df = test_df[test_df['Location'] == source_location]\n",
    "source_df.sort_values(by=['Website'], inplace=True)\n",
    "source_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "translated_z_df = pd.read_csv(f'../synthesized/{target_location}-VAE-Sampling-Z-Translations.csv')\n",
    "translated_z_df = translated_z_df[translated_z_df['Location'] == target_location]\n",
    "translated_z_df.sort_values(by=['Website'], inplace=True)\n",
    "translated_z_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1737580018.961208  230991 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1737580018.961327  230991 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21349 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# models\n",
    "import tensorflow as tf\n",
    "from scripts.translate_and_synthsize import SWDLoss\n",
    "from scripts.train_vae import Sampling, ConvVAE_BatchNorm\n",
    "latent_dim = 96\n",
    "swd_loss = SWDLoss(latent_dim)\n",
    "vae_model = tf.keras.models.load_model(f\"../models-{locations[0]}-{locations[1]}/vae/ci_vae/ConvBased/domain_and_class/{locations[0]}-{locations[1]}-e800-mse1-kl0.01-cl1.0-ConvBatchNorm-ldim96-hdim128.keras\", custom_objects={'ConvVAE_BatchNorm': ConvVAE_BatchNorm, 'Sampling': Sampling})\n",
    "translator = tf.keras.models.load_model(f\"../models-{locations[0]}-{locations[1]}/latent_translator/translator-kl0.01-e200.keras\", custom_objects={'SWDLoss': swd_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.translate_and_synthsize import get_z_embeddings, get_z_translations\n",
    "\n",
    "source_z = get_z_embeddings(source_df.iloc[:, 2:], vae_model)\n",
    "target_z = get_z_embeddings(target_df.iloc[:, 2:], vae_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "def create_simple_dense_classifier(input_dim, num_classes, hidden_units=64, dropout_rate=0.1):\n",
    "    \"\"\"\n",
    "    Creates a simple dense neural network classifier.\n",
    "\n",
    "    Parameters:\n",
    "    - input_dim: int, the number of features in the input data.\n",
    "    - num_classes: int, the number of output classes.\n",
    "    - hidden_units: int, the number of neurons in the hidden layer.\n",
    "    - dropout_rate: float, the dropout rate for regularization.\n",
    "\n",
    "    Returns:\n",
    "    - model: A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(hidden_units, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(hidden_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')  # Softmax for multi-class classification\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',  # Suitable for integer-encoded labels\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on source location z embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0587 - loss: 5.1893\n",
      "Epoch 2/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4016 - loss: 2.3801\n",
      "Epoch 3/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5433 - loss: 1.7005\n",
      "Epoch 4/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5995 - loss: 1.4556\n",
      "Epoch 5/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6390 - loss: 1.2958\n",
      "Epoch 6/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6549 - loss: 1.2085\n",
      "Epoch 7/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6727 - loss: 1.1434\n",
      "Epoch 8/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6815 - loss: 1.1020\n",
      "Epoch 9/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6890 - loss: 1.0897\n",
      "Epoch 10/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6970 - loss: 1.0556\n",
      "Epoch 11/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7043 - loss: 1.0202\n",
      "Epoch 12/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7006 - loss: 1.0262\n",
      "Epoch 13/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 1.0027\n",
      "Epoch 14/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.9765\n",
      "Epoch 15/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.9736\n",
      "Epoch 16/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.9581\n",
      "Epoch 17/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.9476\n",
      "Epoch 18/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.9677\n",
      "Epoch 19/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.9499\n",
      "Epoch 20/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7265 - loss: 0.9307\n",
      "Epoch 21/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7330 - loss: 0.9136\n",
      "Epoch 22/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 0.9207\n",
      "Epoch 23/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7305 - loss: 0.9162\n",
      "Epoch 24/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.9118\n",
      "Epoch 25/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.8964\n",
      "Epoch 26/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.8933\n",
      "Epoch 27/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.8897\n",
      "Epoch 28/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.8775\n",
      "Epoch 29/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.8837\n",
      "Epoch 30/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7454 - loss: 0.8676\n",
      "Epoch 31/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7456 - loss: 0.8754\n",
      "Epoch 32/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7499 - loss: 0.8597\n",
      "Epoch 33/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7435 - loss: 0.8836\n",
      "Epoch 34/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7476 - loss: 0.8499\n",
      "Epoch 35/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7400 - loss: 0.8715\n",
      "Epoch 36/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7451 - loss: 0.8680\n",
      "Epoch 37/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7485 - loss: 0.8627\n",
      "Epoch 38/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.8752\n",
      "Epoch 39/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7458 - loss: 0.8687\n",
      "Epoch 40/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7479 - loss: 0.8369\n",
      "Epoch 41/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7605 - loss: 0.8213\n",
      "Epoch 42/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7546 - loss: 0.8225\n",
      "Epoch 43/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7559 - loss: 0.8402\n",
      "Epoch 44/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7553 - loss: 0.8261\n",
      "Epoch 45/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7552 - loss: 0.8391\n",
      "Epoch 46/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7579 - loss: 0.8185\n",
      "Epoch 47/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7552 - loss: 0.8341\n",
      "Epoch 48/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7535 - loss: 0.8361\n",
      "Epoch 49/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7527 - loss: 0.8227\n",
      "Epoch 50/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7521 - loss: 0.8415\n",
      "Epoch 51/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.8055\n",
      "Epoch 52/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7565 - loss: 0.8228\n",
      "Epoch 53/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7549 - loss: 0.8171\n",
      "Epoch 54/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7575 - loss: 0.8288\n",
      "Epoch 55/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7545 - loss: 0.8167\n",
      "Epoch 56/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7676 - loss: 0.7892\n",
      "Epoch 57/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7653 - loss: 0.7906\n",
      "Epoch 58/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7652 - loss: 0.8189\n",
      "Epoch 59/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7598 - loss: 0.8176\n",
      "Epoch 60/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7559 - loss: 0.8327\n",
      "Epoch 61/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7619 - loss: 0.8093\n",
      "Epoch 62/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7676 - loss: 0.7879\n",
      "Epoch 63/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7631 - loss: 0.8131\n",
      "Epoch 64/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7610 - loss: 0.8040\n",
      "Epoch 65/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.8128\n",
      "Epoch 66/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.8115\n",
      "Epoch 67/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7651 - loss: 0.8064\n",
      "Epoch 68/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7635 - loss: 0.8097\n",
      "Epoch 69/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7577 - loss: 0.8201\n",
      "Epoch 70/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7574 - loss: 0.7922\n",
      "Epoch 71/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7599 - loss: 0.8100\n",
      "Epoch 72/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7625 - loss: 0.8020\n",
      "Epoch 73/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7630 - loss: 0.7941\n",
      "Epoch 74/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7654 - loss: 0.7960\n",
      "Epoch 75/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7663 - loss: 0.7952\n",
      "Epoch 76/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7637 - loss: 0.8126\n",
      "Epoch 77/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7639 - loss: 0.8016\n",
      "Epoch 78/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7649 - loss: 0.7979\n",
      "Epoch 79/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7676 - loss: 0.7783\n",
      "Epoch 80/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7644 - loss: 0.8004\n",
      "Epoch 81/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7599 - loss: 0.8156\n",
      "Epoch 82/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7667 - loss: 0.8033\n",
      "Epoch 83/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7681 - loss: 0.7887\n",
      "Epoch 84/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7677 - loss: 0.8006\n",
      "Epoch 85/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7617 - loss: 0.8066\n",
      "Epoch 86/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7673 - loss: 0.7867\n",
      "Epoch 87/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7655 - loss: 0.7860\n",
      "Epoch 88/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7665 - loss: 0.7872\n",
      "Epoch 89/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7678 - loss: 0.7941\n",
      "Epoch 90/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7677 - loss: 0.7918\n",
      "Epoch 91/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7660 - loss: 0.7861\n",
      "Epoch 92/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7654 - loss: 0.7965\n",
      "Epoch 93/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7668 - loss: 0.7950\n",
      "Epoch 94/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7712 - loss: 0.7754\n",
      "Epoch 95/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7681 - loss: 0.7959\n",
      "Epoch 96/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7695 - loss: 0.7892\n",
      "Epoch 97/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 0.7843\n",
      "Epoch 98/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7646 - loss: 0.7837\n",
      "Epoch 99/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7715 - loss: 0.7715\n",
      "Epoch 100/100\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7653 - loss: 0.7979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x71d50677f410>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scripts.classification as classification \n",
    "le = LabelEncoder()\n",
    "\n",
    "X_train = source_z\n",
    "y_train = le.fit_transform(source_df.Website)\n",
    "X_test = target_z\n",
    "y_test = le.transform(target_df.Website)\n",
    "\n",
    "model = create_simple_dense_classifier(latent_dim, len(test_web_samples))\n",
    "model.fit(X_train, y_train, batch_size = 32, epochs=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step\n",
      "Accuracy: 0.5633\n",
      "F1 Score (weighted): 0.5330\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Convert logits to class labels\n",
    "y_pred_logits = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_logits, axis=1)  # Get class indices with maximum logits\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Use weighted average for imbalanced data\n",
    "print(f\"F1 Score (weighted): {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on translated z embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception originated from\n\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n    self._run_once()\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n    handle._run()\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/events.py\", line 84, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n    result = self._run_cell(\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n    result = runner(coro)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_230991/2960372031.py\", line 11, in <module>\n    model.fit(X_train, y_train, batch_size = 128, epochs=10, shuffle=True)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n    logs = self.train_function(iterator)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n    opt_outputs = multi_step_on_iterator(iterator)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n    result = self._call(*args, **kwds)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n    results = tracing_compilation.call_function(\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n    return function._call_flat(  # pylint: disable=protected-access\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n    return self._inference_function.call_preflattened(args)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n    flat_outputs = self.call_flat(*args)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n    outputs = self._bound_context.call_function(\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/context.py\", line 1683, in call_function\n    outputs = execute.execute(\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\n{{function_node __inference_multi_step_on_iterator_2027963}} Matrix size-incompatible: In[0]: [128,128], In[1]: [96,128]\n\nStack trace for op definition: \nFile \"<frozen runpy>\", line 198, in _run_module_as_main\nFile \"<frozen runpy>\", line 88, in _run_code\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/events.py\", line 84, in _run\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\nFile \"/tmp/ipykernel_230991/2960372031.py\", line 11, in <module>\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 57, in train_step\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 908, in __call__\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/models/sequential.py\", line 213, in call\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/models/functional.py\", line 182, in call\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/models/functional.py\", line 637, in call\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 908, in __call__\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/layers/core/dense.py\", line 144, in call\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 3815, in matmul\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 501, in matmul\n\n\t [[{{node sequential_12_1/dense_33_1/MatMul}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_2027906[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]]\n\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors. [Op:RangeDataset] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m y_test \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(target_df\u001b[38;5;241m.\u001b[39mWebsite)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# model = create_simple_dense_classifier(latent_dim, len(test_web_samples))\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception originated from\n\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n    self._run_once()\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n    handle._run()\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/events.py\", line 84, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n    result = self._run_cell(\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n    result = runner(coro)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_230991/2960372031.py\", line 11, in <module>\n    model.fit(X_train, y_train, batch_size = 128, epochs=10, shuffle=True)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n    logs = self.train_function(iterator)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n    opt_outputs = multi_step_on_iterator(iterator)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n    result = self._call(*args, **kwds)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n    results = tracing_compilation.call_function(\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n    return function._call_flat(  # pylint: disable=protected-access\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n    return self._inference_function.call_preflattened(args)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n    flat_outputs = self.call_flat(*args)\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n    outputs = self._bound_context.call_function(\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/context.py\", line 1683, in call_function\n    outputs = execute.execute(\n  File \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\n{{function_node __inference_multi_step_on_iterator_2027963}} Matrix size-incompatible: In[0]: [128,128], In[1]: [96,128]\n\nStack trace for op definition: \nFile \"<frozen runpy>\", line 198, in _run_module_as_main\nFile \"<frozen runpy>\", line 88, in _run_code\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/asyncio/events.py\", line 84, in _run\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\nFile \"/tmp/ipykernel_230991/2960372031.py\", line 11, in <module>\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 57, in train_step\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 908, in __call__\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/models/sequential.py\", line 213, in call\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/models/functional.py\", line 182, in call\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/models/functional.py\", line 637, in call\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 908, in __call__\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/layers/core/dense.py\", line 144, in call\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 3815, in matmul\nFile \"/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 501, in matmul\n\n\t [[{{node sequential_12_1/dense_33_1/MatMul}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_2027906[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]]\n\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors. [Op:RangeDataset] name: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scripts.classification as classification \n",
    "le = LabelEncoder()\n",
    "\n",
    "X_train = source_df.iloc[:, 2:]\n",
    "y_train = le.fit_transform(source_df.Website)\n",
    "X_test = target_z\n",
    "y_test = le.transform(target_df.Website)\n",
    "\n",
    "# model = create_simple_dense_classifier(latent_dim, len(test_web_samples))\n",
    "model.fit(X_train, y_train, batch_size = 128, epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/929\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 40ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Accuracy: 0.2514\n",
      "F1 Score (weighted): 0.2255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Convert logits to class labels\n",
    "y_pred_logits = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_logits, axis=1)  # Get class indices with maximum logits\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Use weighted average for imbalanced data\n",
    "print(f\"F1 Score (weighted): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Both translated and source z embeddings for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e19372/anaconda3/envs/doh_synth_env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1131 - loss: 4.5472\n",
      "Epoch 2/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.4210 - loss: 2.1812\n",
      "Epoch 3/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4987 - loss: 1.8455\n",
      "Epoch 4/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5285 - loss: 1.7054\n",
      "Epoch 5/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5466 - loss: 1.6341\n",
      "Epoch 6/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5520 - loss: 1.5916\n",
      "Epoch 7/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5607 - loss: 1.5679\n",
      "Epoch 8/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5715 - loss: 1.5280\n",
      "Epoch 9/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5717 - loss: 1.5290\n",
      "Epoch 10/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5772 - loss: 1.4975\n",
      "Epoch 11/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5829 - loss: 1.4874\n",
      "Epoch 12/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5824 - loss: 1.4681\n",
      "Epoch 13/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5871 - loss: 1.4675\n",
      "Epoch 14/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5884 - loss: 1.4550\n",
      "Epoch 15/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5905 - loss: 1.4576\n",
      "Epoch 16/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5914 - loss: 1.4476\n",
      "Epoch 17/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5926 - loss: 1.4274\n",
      "Epoch 18/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6021 - loss: 1.4090\n",
      "Epoch 19/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5953 - loss: 1.4257\n",
      "Epoch 20/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5952 - loss: 1.4352\n",
      "Epoch 21/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 1.4121\n",
      "Epoch 22/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 1.4133\n",
      "Epoch 23/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 1.4059\n",
      "Epoch 24/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6024 - loss: 1.3941\n",
      "Epoch 25/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 1.3771\n",
      "Epoch 26/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6037 - loss: 1.3953\n",
      "Epoch 27/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 1.3964\n",
      "Epoch 28/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6021 - loss: 1.4094\n",
      "Epoch 29/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 1.3894\n",
      "Epoch 30/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6107 - loss: 1.3767\n",
      "Epoch 31/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6088 - loss: 1.3933\n",
      "Epoch 32/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6116 - loss: 1.3804\n",
      "Epoch 33/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6093 - loss: 1.3760\n",
      "Epoch 34/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6104 - loss: 1.3812\n",
      "Epoch 35/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6132 - loss: 1.3768\n",
      "Epoch 36/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6112 - loss: 1.3839\n",
      "Epoch 37/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6083 - loss: 1.3741\n",
      "Epoch 38/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6095 - loss: 1.3802\n",
      "Epoch 39/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6176 - loss: 1.3480\n",
      "Epoch 40/40\n",
      "\u001b[1m1857/1857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6125 - loss: 1.3637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x71d518cb93d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scripts.classification as classification \n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "X_train = np.concatenate([source_z, get_z_translations(source_z, translator)])\n",
    "\n",
    "y_train = le.fit_transform(source_df.Website)\n",
    "y_train = np.concatenate([y_train, le.transform(source_df.Website)])\n",
    "\n",
    "X_test = target_z\n",
    "y_test = le.transform(target_df.Website)\n",
    "\n",
    "model = create_simple_dense_classifier(latent_dim, len(test_web_samples))\n",
    "model.fit(X_train, y_train, batch_size = 32, epochs=40, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step\n",
      "Accuracy: 0.5856\n",
      "F1 Score (weighted): 0.5610\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Convert logits to class labels\n",
    "y_pred_logits = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_logits, axis=1)  # Get class indices with maximum logits\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Use weighted average for imbalanced data\n",
    "print(f\"F1 Score (weighted): {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doh_synth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
