{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Loading Dataset...\n",
      "Training Websites: [1309, 228, 51, 563, 501, 457, 285, 209, 1385, 1116, 178, 1209, 864, 65, 61, 191, 447, 476, 1034, 1232, 54, 1149, 407, 1466, 1330, 1436, 1490, 859, 451, 919, 1206, 569, 13, 326, 1429, 865, 696, 1468, 318, 440, 689, 1492, 189, 778, 198, 735, 704, 1236, 541, 88, 940, 1098, 255, 775, 161, 1130, 600, 1287, 1266, 740, 1182, 393, 142, 93, 1354, 466, 592, 163, 1482, 206, 1456, 1462, 928, 1301, 747, 333, 758, 727, 429, 1372, 546, 1399, 1327, 146, 1247, 1300, 350, 1093, 1495, 334, 946, 777, 552, 1310, 1140, 449, 1402, 664, 114, 469, 1486, 646, 821, 548, 135, 432, 1161, 644, 435, 1342, 1022, 810, 1316, 939, 292, 542, 1493, 505, 1478, 1103, 538, 1197, 877, 1195, 817, 741, 1404, 283, 1043, 1010, 186, 96, 224, 313, 1285, 327, 1487, 1221, 130, 788, 781, 1220, 958, 1083, 514, 1133, 23, 234, 1099, 1419, 1312, 1463, 1498, 601, 890, 323, 929, 6, 539, 1025, 365, 1039, 217, 1280, 611, 1308, 1338, 1415, 1477, 1366, 765, 330, 1104, 1086, 1, 1226, 663, 1000, 39, 229, 743, 629, 490, 118, 493, 1393, 1445, 175, 995, 141, 1090, 257, 262, 973, 1125, 338, 1384, 1080, 1242, 866, 433, 1417, 411, 638, 1375, 764, 897, 1059, 924, 247, 507, 460, 131, 692, 43, 1204, 1134, 471, 1205, 1471, 14, 145, 120, 468, 138, 64, 676, 1278, 1052, 487, 570, 994, 438, 1298, 270, 1169, 1180, 968, 497, 1262, 833, 389, 193, 1455, 882, 725, 867, 841, 956, 110, 201, 124, 824, 694, 223, 509, 392, 1258, 1448, 918, 287, 1363, 375, 1269, 947, 511, 154, 907, 1127, 200, 103, 1107, 30, 1484, 484, 340, 832, 1268, 985, 437, 1397, 1277, 337, 776, 4, 799, 543, 931, 584, 1414, 1138, 996, 317, 388, 607, 445, 119, 1186, 1110, 1248, 642, 117, 102, 1196, 976, 1029, 1087, 322, 116, 1040, 164, 380, 140, 139, 481, 826, 245, 1166, 504, 81, 167, 858, 1157, 1070, 647, 534, 418, 643, 488, 1213, 1388, 268, 614, 936, 1175, 148, 19, 938, 1153, 204, 150, 1101, 436, 1036, 1170, 271, 714, 1187, 500, 756, 583, 1344, 1293, 1112, 619, 1356, 16, 1135, 613, 212, 275, 1451, 236, 219, 1435, 1461, 557, 577, 431, 702, 416, 540, 1035, 1322, 1355, 104, 1457, 1253, 566, 90, 7, 683, 267, 536, 1328, 904, 875, 1163, 1320, 1233, 305, 73, 1150, 303, 880, 261, 85, 631, 746, 1263, 732, 430, 1234, 210, 724, 1223, 316, 1225, 332, 362, 844, 50, 367, 680, 843, 508, 1350, 1476, 221, 783, 79, 963, 455, 408, 942, 716, 625, 1434, 456, 48, 395, 816, 672, 1452, 1437, 571, 719, 1371, 818, 678, 56, 1137, 1174, 1339, 1155, 78, 222, 889, 707, 1199, 893, 1047, 1058, 1360, 1426, 521, 1120, 1049, 3, 403, 745, 883, 143, 1273, 1050, 1447, 615, 633, 836, 668, 1332, 605, 260, 1243, 861, 1216, 356, 630, 582, 308, 415, 561, 853, 0, 311, 293, 215, 1460, 804, 593, 621, 670, 329, 1431, 452, 1005, 691, 218, 523, 1092, 812, 922, 982, 815, 753, 173, 674, 86, 290, 527, 679, 648, 634, 343, 95, 838, 974, 769, 240, 688, 1207, 230, 825, 203, 1159, 25, 47, 250, 486, 1073, 870, 786, 74, 1072, 424, 1480, 1392, 589, 199, 1454, 713, 1438, 506, 409, 249, 151, 671, 1453, 5, 914, 768, 881, 1046, 906, 109, 797, 1391, 1367, 180, 823, 712, 530, 475, 1497, 1066, 1481, 868, 1200, 467, 136, 820, 937, 1118, 1055, 572, 609, 324, 773, 912, 453, 627, 834, 736, 913, 516, 1177, 850, 1018, 1071, 162, 761, 1255, 971, 1288, 265, 997, 253, 860, 652, 1420, 784, 796, 533, 496, 641, 244, 281, 450, 1079, 730, 1491, 981, 278, 986, 1364, 553, 82, 1406, 1201, 1048, 1026, 710, 156, 723, 1136, 1418, 965, 417, 1304, 555, 477, 425, 63, 211, 852, 1241, 398, 1235, 598, 1386, 20, 1302, 962, 1045, 1171, 1390, 360, 1109, 771, 399, 1421, 551, 1329, 752, 559, 819, 617, 225, 499, 1075, 279, 446, 1261, 29, 863, 344, 684, 695, 1295, 414, 1374, 169, 478, 1361, 637, 1144, 27, 1190, 606, 1132, 1060, 1449, 1380, 658, 1267, 1275, 472, 1369, 1439, 266, 1469, 335, 216, 465, 1410, 345, 779, 809, 284, 770, 1131, 258, 83, 1185, 1146, 767, 1407, 53, 358, 1111, 665, 70, 667, 41, 772, 31, 903, 1160, 1472, 636, 1377, 894, 129, 1126, 685, 1198, 1343, 1245, 1006, 1074, 1307, 377, 171, 620, 1009, 960, 774, 1179, 1283, 1250, 1433, 26, 319, 857, 693, 384, 406, 1351, 1376, 77, 1219, 1051, 1231, 248, 1124, 959, 1020, 700, 1167, 123, 579, 42, 355, 545, 1208, 677, 379, 862, 518, 1323, 349, 12, 1238, 1411, 108, 443, 370, 650, 470, 803, 1284, 941, 1057, 666, 276, 1389, 848, 495, 851, 984, 749, 274, 1115, 251, 1450, 1383, 461, 955, 1427, 1381, 624, 1259, 802, 1240, 1031, 957, 1091, 999, 1252, 1337, 363, 264, 348, 286, 610, 282, 1428, 10, 529, 195, 87, 1290, 1129, 1151, 568, 246, 1270, 661, 502, 458, 17, 1362, 301, 226, 830, 1444, 1475, 595, 949, 1024, 1121, 926, 352, 943, 1496, 871, 1017, 464, 277, 1345, 1334, 1105, 1440, 197, 1148, 122, 1396, 1123, 196, 1081, 902, 900, 603, 537, 1335, 289, 1378, 1256, 1106, 232, 369, 183, 309, 1279, 1194, 1408, 280, 46, 55, 659, 299, 699, 953, 105, 728, 587, 291, 480, 1317, 1336, 687, 188, 52, 798, 489, 1191, 66, 410, 503, 75, 590, 1479, 155, 152, 576, 1015, 989, 254, 121, 1064, 426, 231, 535, 856, 703, 920, 304, 439, 312, 1485, 101, 1405, 807, 1265, 944, 160, 1183, 177, 565, 76, 574, 2, 1173, 585, 898, 298, 33, 237, 295, 987, 901, 72, 239, 662, 202, 656, 763, 978, 596, 272, 1272, 1108, 580, 828, 314, 921, 1373, 127, 479, 594, 412, 887, 512, 1382, 448, 1038, 40, 442, 748, 256, 1423, 1474, 1352, 21, 1139, 1260, 179, 599, 1004, 801, 185, 878, 1346, 528, 522, 1023, 567, 341, 328, 886, 792, 1021, 717, 168, 1096, 737, 1178, 147, 339, 483, 205, 734, 586, 1042, 18, 1314, 45, 1313, 618, 165, 59, 1069, 1430, 532, 263, 422, 1016, 336, 1063, 651, 988, 1210, 1061, 1368, 905, 519, 909, 387, 934, 320, 800, 837, 681, 1333, 930, 896, 67, 1085, 840, 892, 357, 1158, 62, 626, 1192, 1128, 1251, 1078, 1459, 1100, 159, 698, 1119, 829, 208, 1306, 115, 1422, 58, 1488, 60, 331, 1228, 1054, 1282, 366, 149, 1027, 361, 1202, 578, 427, 1089, 241, 932, 233, 731, 967, 895, 97, 306, 1394, 382, 69, 35, 908, 855, 404, 849, 174, 822, 259, 806, 1325, 144, 371, 744, 300, 296, 1217, 972, 935, 1347, 525, 428, 176, 170, 423, 390, 1379, 1257, 873, 1189, 711, 459, 1044, 1271, 421, 1203, 1473, 22, 910, 242, 1214, 1326, 1398, 726, 1424, 750, 517, 639, 1274, 649, 302, 970, 811, 842, 364, 269, 697, 1483, 1172, 1458, 808, 891, 38, 888, 1395, 1222, 757, 751, 755, 524, 1246, 1011, 273, 194, 378, 721, 1403, 612, 1318, 1412, 1019, 1218, 645, 462, 604, 622, 1053, 1088, 923, 1499, 227, 831, 153, 911, 1353, 166, 28, 975, 628, 1324, 220, 660, 125, 1154, 1188, 560, 92, 1370, 89, 1147, 1237, 1165, 759, 564, 791, 1387, 1012]\n",
      "Training Locations: ['LOC2', 'LOC3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaush\\Documents\\Python Projects\\DoH-Synthesis\\code\\scripts\\init_dataset.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.sort_values(by=[\"Location\"], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Website</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.714089</td>\n",
       "      <td>0.541197</td>\n",
       "      <td>0.391921</td>\n",
       "      <td>-0.400778</td>\n",
       "      <td>-0.266345</td>\n",
       "      <td>-0.522526</td>\n",
       "      <td>0.023889</td>\n",
       "      <td>-0.261817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.093792</td>\n",
       "      <td>-1.273349</td>\n",
       "      <td>-2.142801</td>\n",
       "      <td>1.205098</td>\n",
       "      <td>1.879002</td>\n",
       "      <td>2.139593</td>\n",
       "      <td>1.482513</td>\n",
       "      <td>2.382939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>1.401091</td>\n",
       "      <td>-1.636258</td>\n",
       "      <td>0.527106</td>\n",
       "      <td>0.354928</td>\n",
       "      <td>-0.017609</td>\n",
       "      <td>-0.049260</td>\n",
       "      <td>-0.177300</td>\n",
       "      <td>-0.412692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>-0.831599</td>\n",
       "      <td>0.662167</td>\n",
       "      <td>0.527106</td>\n",
       "      <td>0.354928</td>\n",
       "      <td>-0.017609</td>\n",
       "      <td>-0.049260</td>\n",
       "      <td>-0.177300</td>\n",
       "      <td>-0.412692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOC2</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.093792</td>\n",
       "      <td>-1.152379</td>\n",
       "      <td>-2.007616</td>\n",
       "      <td>0.827245</td>\n",
       "      <td>1.630266</td>\n",
       "      <td>1.666328</td>\n",
       "      <td>1.281324</td>\n",
       "      <td>2.311938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.10277</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.152216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location  Website         0         1         2         3         4  \\\n",
       "0     LOC2        0 -0.714089  0.541197  0.391921 -0.400778 -0.266345   \n",
       "1     LOC2     1006  0.093792 -1.273349 -2.142801  1.205098  1.879002   \n",
       "2     LOC2     1006  1.401091 -1.636258  0.527106  0.354928 -0.017609   \n",
       "3     LOC2     1006 -0.831599  0.662167  0.527106  0.354928 -0.017609   \n",
       "4     LOC2     1006  0.093792 -1.152379 -2.007616  0.827245  1.630266   \n",
       "\n",
       "          5         6         7  ...       118      119       120       121  \\\n",
       "0 -0.522526  0.023889 -0.261817  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "1  2.139593  1.482513  2.382939  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "2 -0.049260 -0.177300 -0.412692  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "3 -0.049260 -0.177300 -0.412692  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "4  1.666328  1.281324  2.311938  ...  0.125986  0.10277  0.092495  0.043004   \n",
       "\n",
       "        122       123       124       125       126       127  \n",
       "0  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "1  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "2  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "3  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "4  0.158904  0.119506  0.099445  0.083843  0.037226  0.152216  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scripts.init_gpu as init_gpu\n",
    "import scripts.init_dataset as init_dataset\n",
    "from scripts.triplet_functions import n_neurons\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "init_gpu.initialize_gpus()\n",
    "\n",
    "locations = ['LOC2', 'LOC3']\n",
    "\n",
    "print(\"Loading Dataset...\")\n",
    "# load the dataset\n",
    "df = pd.read_csv(\n",
    "    f\"../dataset/processed/{locations[0]}-{locations[1]}-scaled-balanced.csv\")\n",
    "\n",
    "length = len(df.columns) - 2  # subtract the two label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaush\\AppData\\Local\\Temp\\ipykernel_42828\\4085505363.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_df.sort_values(by=['Website'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 148500 entries, 0 to 148499\n",
      "Columns: 130 entries, Location to 127\n",
      "dtypes: float64(128), int64(1), object(1)\n",
      "memory usage: 147.3+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaush\\AppData\\Local\\Temp\\ipykernel_42828\\4085505363.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  source_df.sort_values(by=['Website'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# dataset for the classification\n",
    "source_location, target_location = locations\n",
    "\n",
    "target_df = df[df['Location'] == target_location]\n",
    "target_df.sort_values(by=['Website'], inplace=True)\n",
    "target_df.reset_index(drop=True, inplace=True)\n",
    "target_df.head(20)\n",
    "\n",
    "source_df = df[df['Location'] == source_location]\n",
    "source_df.sort_values(by=['Website'], inplace=True)\n",
    "source_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "source_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Example function to extract features from a single trace.\n",
    "def extract_features_from_trace(trace):\n",
    "    \"\"\"\n",
    "    Given a trace (a list of integers representing TLS record sizes),\n",
    "    extract features as a dictionary containing counts for:\n",
    "      - Unigrams: individual TLS record sizes.\n",
    "      - Bigrams: pairs of consecutive TLS record sizes.\n",
    "      - Burst features: grouping consecutive packets with the same sign.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # 1. Unigrams: count each TLS record size.\n",
    "    for token in trace:\n",
    "        key = f\"U_{token}\"\n",
    "        features[key] = features.get(key, 0) + 1\n",
    "\n",
    "    # 2. Bigrams: count each pair of consecutive TLS record sizes.\n",
    "    for i in range(len(trace) - 1):\n",
    "        key = f\"B_{trace[i]}_{trace[i+1]}\"\n",
    "        features[key] = features.get(key, 0) + 1\n",
    "\n",
    "    # 3. Burst features:\n",
    "    #    Define a burst as a sequence of consecutive packets with the same sign.\n",
    "    bursts = []\n",
    "    if trace:\n",
    "        current_burst = [trace[0]]\n",
    "        for num in trace[1:]:\n",
    "            # Check if the current number has the same sign as the last number in current burst.\n",
    "            if (num >= 0 and current_burst[-1] >= 0) or (num < 0 and current_burst[-1] < 0):\n",
    "                current_burst.append(num)\n",
    "            else:\n",
    "                bursts.append(current_burst)\n",
    "                current_burst = [num]\n",
    "        bursts.append(current_burst)\n",
    "    \n",
    "    # Burst Unigrams: use the sum of values in each burst.\n",
    "    burst_unigrams = [sum(burst) for burst in bursts]\n",
    "    for token in burst_unigrams:\n",
    "        key = f\"BU_{token}\"\n",
    "        features[key] = features.get(key, 0) + 1\n",
    "\n",
    "    # Burst Bigrams: count consecutive burst sums as pairs.\n",
    "    for i in range(len(burst_unigrams) - 1):\n",
    "        key = f\"BB_{burst_unigrams[i]}_{burst_unigrams[i+1]}\"\n",
    "        features[key] = features.get(key, 0) + 1\n",
    "\n",
    "    return features\n",
    "\n",
    "# def extract_features_from_df(df):\n",
    "#     # Helper function to extract the trace from a DataFrame row.\n",
    "#     def get_trace_from_row(row):\n",
    "#         \"\"\"\n",
    "#         Extracts the DNS trace from a DataFrame row.\n",
    "#         Assumes that the trace values are stored in the columns starting at index 2.\n",
    "#         Drops any NaN values and converts each entry to an integer.\n",
    "#         \"\"\"\n",
    "#         trace = row.iloc[2:].dropna().tolist()\n",
    "#         return [int(x) for x in trace]\n",
    "\n",
    "#     # Iterate over the DataFrame rows.\n",
    "#     feature_dicts = []\n",
    "#     for idx, row in df.iterrows():\n",
    "#         trace = get_trace_from_row(row)\n",
    "#         feats = extract_features_from_trace(trace)\n",
    "#         feature_dicts.append(feats)\n",
    "\n",
    "#     # Use DictVectorizer to transform our list of feature dictionaries into a fixed-length matrix.\n",
    "#     vectorizer = DictVectorizer(sparse=False)\n",
    "#     X_features = vectorizer.fit_transform(feature_dicts)\n",
    "\n",
    "#     # Now, X_features is a 2D numpy array where each row is a fixed-length vector representing one trace.\n",
    "#     print(\"Feature matrix shape:\", X_features.shape)\n",
    "#     print(\"Feature names:\", vectorizer.get_feature_names_out())\n",
    "#     return X_features, vectorizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training feature matrix shape: (148500, 553)\n",
      "Test feature matrix shape: (148500, 553)\n",
      "Feature names: ['BB_-10_0' 'BB_-10_1' 'BB_-10_2' 'BB_-10_3' 'BB_-10_5' 'BB_-10_7'\n",
      " 'BB_-10_8' 'BB_-11_0' 'BB_-11_1' 'BB_-11_2' 'BB_-11_3' 'BB_-11_5'\n",
      " 'BB_-12_0' 'BB_-12_1' 'BB_-12_2' 'BB_-12_3' 'BB_-12_4' 'BB_-12_5'\n",
      " 'BB_-12_6' 'BB_-12_7' 'BB_-13_0' 'BB_-13_1' 'BB_-13_2' 'BB_-13_3'\n",
      " 'BB_-13_4' 'BB_-13_5' 'BB_-13_6' 'BB_-14_0' 'BB_-14_1' 'BB_-14_2'\n",
      " 'BB_-14_3' 'BB_-15_0' 'BB_-15_1' 'BB_-15_2' 'BB_-15_3' 'BB_-15_4'\n",
      " 'BB_-15_6' 'BB_-15_7' 'BB_-15_8' 'BB_-16_0' 'BB_-16_1' 'BB_-16_2'\n",
      " 'BB_-16_3' 'BB_-17_0' 'BB_-17_1' 'BB_-17_2' 'BB_-18_0' 'BB_-18_1'\n",
      " 'BB_-18_2' 'BB_-19_0' 'BB_-19_1' 'BB_-19_3' 'BB_-1_0' 'BB_-1_1'\n",
      " 'BB_-1_10' 'BB_-1_12' 'BB_-1_16' 'BB_-1_2' 'BB_-1_25' 'BB_-1_3' 'BB_-1_4'\n",
      " 'BB_-1_5' 'BB_-1_6' 'BB_-1_7' 'BB_-1_8' 'BB_-1_9' 'BB_-20_0' 'BB_-20_2'\n",
      " 'BB_-21_0' 'BB_-21_1' 'BB_-22_0' 'BB_-23_0' 'BB_-24_0' 'BB_-25_0'\n",
      " 'BB_-25_1' 'BB_-27_0' 'BB_-27_1' 'BB_-28_0' 'BB_-29_0' 'BB_-2_0'\n",
      " 'BB_-2_1' 'BB_-2_10' 'BB_-2_11' 'BB_-2_12' 'BB_-2_13' 'BB_-2_15'\n",
      " 'BB_-2_16' 'BB_-2_2' 'BB_-2_3' 'BB_-2_4' 'BB_-2_5' 'BB_-2_6' 'BB_-2_7'\n",
      " 'BB_-2_8' 'BB_-2_9' 'BB_-31_0' 'BB_-31_2' 'BB_-3_0' 'BB_-3_1' 'BB_-3_12'\n",
      " 'BB_-3_14' 'BB_-3_2' 'BB_-3_3' 'BB_-3_4' 'BB_-3_5' 'BB_-3_6' 'BB_-3_7'\n",
      " 'BB_-3_8' 'BB_-3_9' 'BB_-4_0' 'BB_-4_1' 'BB_-4_10' 'BB_-4_11' 'BB_-4_2'\n",
      " 'BB_-4_3' 'BB_-4_4' 'BB_-4_5' 'BB_-4_6' 'BB_-4_7' 'BB_-4_8' 'BB_-4_9'\n",
      " 'BB_-5_0' 'BB_-5_1' 'BB_-5_2' 'BB_-5_3' 'BB_-5_4' 'BB_-5_5' 'BB_-5_6'\n",
      " 'BB_-5_7' 'BB_-5_9' 'BB_-6_0' 'BB_-6_1' 'BB_-6_2' 'BB_-6_3' 'BB_-6_4'\n",
      " 'BB_-6_5' 'BB_-6_6' 'BB_-6_7' 'BB_-6_8' 'BB_-6_9' 'BB_-7_0' 'BB_-7_1'\n",
      " 'BB_-7_2' 'BB_-7_3' 'BB_-7_4' 'BB_-7_5' 'BB_-7_6' 'BB_-8_0' 'BB_-8_1'\n",
      " 'BB_-8_2' 'BB_-8_3' 'BB_-8_4' 'BB_-8_5' 'BB_-8_6' 'BB_-8_7' 'BB_-8_9'\n",
      " 'BB_-9_0' 'BB_-9_1' 'BB_-9_11' 'BB_-9_2' 'BB_-9_3' 'BB_-9_4' 'BB_0_-1'\n",
      " 'BB_0_-10' 'BB_0_-11' 'BB_0_-12' 'BB_0_-13' 'BB_0_-14' 'BB_0_-15'\n",
      " 'BB_0_-2' 'BB_0_-3' 'BB_0_-4' 'BB_0_-5' 'BB_0_-6' 'BB_0_-7' 'BB_0_-8'\n",
      " 'BB_0_-9' 'BB_10_-2' 'BB_10_-4' 'BB_11_-3' 'BB_11_-4' 'BB_12_-2'\n",
      " 'BB_12_-3' 'BB_13_-4' 'BB_14_-2' 'BB_15_-3' 'BB_16_-3' 'BB_1_-1'\n",
      " 'BB_1_-10' 'BB_1_-11' 'BB_1_-12' 'BB_1_-13' 'BB_1_-14' 'BB_1_-2'\n",
      " 'BB_1_-3' 'BB_1_-4' 'BB_1_-5' 'BB_1_-6' 'BB_1_-7' 'BB_1_-8' 'BB_1_-9'\n",
      " 'BB_2_-1' 'BB_2_-10' 'BB_2_-11' 'BB_2_-12' 'BB_2_-13' 'BB_2_-14'\n",
      " 'BB_2_-15' 'BB_2_-16' 'BB_2_-17' 'BB_2_-18' 'BB_2_-19' 'BB_2_-2'\n",
      " 'BB_2_-20' 'BB_2_-21' 'BB_2_-23' 'BB_2_-25' 'BB_2_-27' 'BB_2_-28'\n",
      " 'BB_2_-29' 'BB_2_-3' 'BB_2_-31' 'BB_2_-4' 'BB_2_-5' 'BB_2_-6' 'BB_2_-7'\n",
      " 'BB_2_-8' 'BB_2_-9' 'BB_3_-1' 'BB_3_-10' 'BB_3_-11' 'BB_3_-19' 'BB_3_-2'\n",
      " 'BB_3_-20' 'BB_3_-22' 'BB_3_-24' 'BB_3_-3' 'BB_3_-4' 'BB_3_-5' 'BB_3_-6'\n",
      " 'BB_3_-7' 'BB_3_-8' 'BB_3_-9' 'BB_4_-1' 'BB_4_-10' 'BB_4_-12' 'BB_4_-13'\n",
      " 'BB_4_-2' 'BB_4_-20' 'BB_4_-23' 'BB_4_-25' 'BB_4_-3' 'BB_4_-31' 'BB_4_-4'\n",
      " 'BB_4_-5' 'BB_4_-6' 'BB_4_-7' 'BB_4_-8' 'BB_4_-9' 'BB_5_-1' 'BB_5_-10'\n",
      " 'BB_5_-12' 'BB_5_-13' 'BB_5_-14' 'BB_5_-15' 'BB_5_-18' 'BB_5_-2'\n",
      " 'BB_5_-24' 'BB_5_-3' 'BB_5_-4' 'BB_5_-5' 'BB_5_-6' 'BB_5_-7' 'BB_5_-8'\n",
      " 'BB_5_-9' 'BB_6_-1' 'BB_6_-13' 'BB_6_-14' 'BB_6_-15' 'BB_6_-16'\n",
      " 'BB_6_-17' 'BB_6_-2' 'BB_6_-24' 'BB_6_-3' 'BB_6_-4' 'BB_6_-5' 'BB_6_-6'\n",
      " 'BB_6_-7' 'BB_6_-8' 'BB_6_-9' 'BB_7_-1' 'BB_7_-12' 'BB_7_-13' 'BB_7_-14'\n",
      " 'BB_7_-15' 'BB_7_-2' 'BB_7_-3' 'BB_7_-4' 'BB_7_-5' 'BB_7_-6' 'BB_7_-7'\n",
      " 'BB_7_-8' 'BB_7_-9' 'BB_8_-1' 'BB_8_-13' 'BB_8_-2' 'BB_8_-3' 'BB_8_-4'\n",
      " 'BB_8_-5' 'BB_8_-6' 'BB_8_-7' 'BB_9_-1' 'BB_9_-13' 'BB_9_-2' 'BB_9_-3'\n",
      " 'BB_9_-4' 'BB_9_-5' 'BB_9_-6' 'BB_9_-8' 'BB_9_-9' 'BU_-1' 'BU_-10'\n",
      " 'BU_-11' 'BU_-12' 'BU_-13' 'BU_-14' 'BU_-15' 'BU_-16' 'BU_-17' 'BU_-18'\n",
      " 'BU_-19' 'BU_-2' 'BU_-20' 'BU_-21' 'BU_-22' 'BU_-23' 'BU_-24' 'BU_-25'\n",
      " 'BU_-27' 'BU_-28' 'BU_-29' 'BU_-3' 'BU_-31' 'BU_-4' 'BU_-5' 'BU_-6'\n",
      " 'BU_-7' 'BU_-8' 'BU_-9' 'BU_0' 'BU_1' 'BU_10' 'BU_11' 'BU_12' 'BU_13'\n",
      " 'BU_14' 'BU_15' 'BU_16' 'BU_2' 'BU_25' 'BU_3' 'BU_4' 'BU_5' 'BU_6' 'BU_7'\n",
      " 'BU_8' 'BU_9' 'B_-10_-2' 'B_-10_-4' 'B_-10_0' 'B_-11_-4' 'B_-11_0'\n",
      " 'B_-11_1' 'B_-12_-4' 'B_-12_0' 'B_-13_-4' 'B_-13_0' 'B_-13_1' 'B_-14_0'\n",
      " 'B_-15_0' 'B_-15_1' 'B_-16_0' 'B_-17_0' 'B_-18_0' 'B_-19_0' 'B_-1_-1'\n",
      " 'B_-1_-2' 'B_-1_-3' 'B_-1_-4' 'B_-1_-5' 'B_-1_-6' 'B_-1_-7' 'B_-1_-9'\n",
      " 'B_-1_0' 'B_-1_1' 'B_-1_2' 'B_-1_3' 'B_-20_0' 'B_-21_0' 'B_-22_0'\n",
      " 'B_-23_0' 'B_-25_0' 'B_-27_0' 'B_-28_0' 'B_-29_0' 'B_-2_-1' 'B_-2_-11'\n",
      " 'B_-2_-14' 'B_-2_-16' 'B_-2_-2' 'B_-2_-21' 'B_-2_-22' 'B_-2_-23'\n",
      " 'B_-2_-29' 'B_-2_-3' 'B_-2_-4' 'B_-2_-5' 'B_-2_-6' 'B_-2_0' 'B_-2_1'\n",
      " 'B_-2_2' 'B_-2_3' 'B_-31_0' 'B_-3_-1' 'B_-3_-2' 'B_-3_-21' 'B_-3_-3'\n",
      " 'B_-3_-4' 'B_-3_-5' 'B_-3_-6' 'B_-3_-7' 'B_-3_-8' 'B_-3_0' 'B_-3_1'\n",
      " 'B_-3_2' 'B_-3_3' 'B_-4_-1' 'B_-4_-2' 'B_-4_-3' 'B_-4_-6' 'B_-4_-7'\n",
      " 'B_-4_0' 'B_-4_1' 'B_-5_-1' 'B_-5_-2' 'B_-5_0' 'B_-5_1' 'B_-5_2' 'B_-6_0'\n",
      " 'B_-6_1' 'B_-6_2' 'B_-7_0' 'B_-7_1' 'B_-7_2' 'B_-8_-4' 'B_-8_0' 'B_-8_1'\n",
      " 'B_-9_-4' 'B_-9_0' 'B_-9_1' 'B_0_-1' 'B_0_-10' 'B_0_-11' 'B_0_-12'\n",
      " 'B_0_-13' 'B_0_-14' 'B_0_-15' 'B_0_-16' 'B_0_-17' 'B_0_-18' 'B_0_-19'\n",
      " 'B_0_-2' 'B_0_-20' 'B_0_-21' 'B_0_-22' 'B_0_-23' 'B_0_-25' 'B_0_-27'\n",
      " 'B_0_-28' 'B_0_-29' 'B_0_-3' 'B_0_-31' 'B_0_-4' 'B_0_-5' 'B_0_-6'\n",
      " 'B_0_-7' 'B_0_-8' 'B_0_-9' 'B_0_0' 'B_0_1' 'B_0_2' 'B_0_3' 'B_0_4'\n",
      " 'B_1_-1' 'B_1_-11' 'B_1_-2' 'B_1_-3' 'B_1_-4' 'B_1_-5' 'B_1_-6' 'B_1_-7'\n",
      " 'B_1_-8' 'B_1_-9' 'B_1_0' 'B_1_1' 'B_1_2' 'B_1_3' 'B_2_-2' 'B_2_-3'\n",
      " 'B_2_-4' 'B_2_-5' 'B_2_-6' 'B_2_-7' 'B_2_0' 'B_2_1' 'B_2_2' 'B_3_0'\n",
      " 'B_3_1' 'B_3_2' 'B_4_1' 'U_-1' 'U_-10' 'U_-11' 'U_-12' 'U_-13' 'U_-14'\n",
      " 'U_-15' 'U_-16' 'U_-17' 'U_-18' 'U_-19' 'U_-2' 'U_-20' 'U_-21' 'U_-22'\n",
      " 'U_-23' 'U_-25' 'U_-27' 'U_-28' 'U_-29' 'U_-3' 'U_-31' 'U_-4' 'U_-5'\n",
      " 'U_-6' 'U_-7' 'U_-8' 'U_-9' 'U_0' 'U_1' 'U_2' 'U_3' 'U_4']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def extract_features_from_datasets(train_df, test_df):\n",
    "    # Helper function to extract the trace from a DataFrame row.\n",
    "    def get_trace_from_row(row):\n",
    "        \"\"\"\n",
    "        Extracts the DNS trace from a DataFrame row.\n",
    "        Assumes that the trace values are stored in the columns starting at index 2.\n",
    "        Drops any NaN values and converts each entry to an integer.\n",
    "        \"\"\"\n",
    "        trace = row.iloc[2:].dropna().tolist()\n",
    "        return [int(x) for x in trace]\n",
    "    \n",
    "    # Process training dataset.\n",
    "    train_feature_dicts = []\n",
    "    for idx, row in train_df.iterrows():\n",
    "        trace = get_trace_from_row(row)\n",
    "        feats = extract_features_from_trace(trace)  # Assumes extract_features_from_trace is defined.\n",
    "        train_feature_dicts.append(feats)\n",
    "    \n",
    "    # Process test dataset.\n",
    "    test_feature_dicts = []\n",
    "    for idx, row in test_df.iterrows():\n",
    "        trace = get_trace_from_row(row)\n",
    "        feats = extract_features_from_trace(trace)  # Assumes extract_features_from_trace is defined.\n",
    "        test_feature_dicts.append(feats)\n",
    "    \n",
    "    # Use DictVectorizer: fit on training and transform both datasets.\n",
    "    vectorizer = DictVectorizer(sparse=False)\n",
    "    X_train = vectorizer.fit_transform(train_feature_dicts)\n",
    "    X_test = vectorizer.transform(test_feature_dicts)\n",
    "    \n",
    "    print(\"Training feature matrix shape:\", X_train.shape)\n",
    "    print(\"Test feature matrix shape:\", X_test.shape)\n",
    "    print(\"Feature names:\", vectorizer.get_feature_names_out())\n",
    "    \n",
    "    return X_train, X_test, vectorizer\n",
    "\n",
    "X_train, X_test, vectorizer = extract_features_from_datasets(source_df, target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "could not allocate 1572864000 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m y_test \u001b[38;5;241m=\u001b[39m target_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWebsite\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      7\u001b[0m rf_clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mrf_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m y_pred_rf \u001b[38;5;241m=\u001b[39m rf_clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, y_pred_rf))\n",
      "File \u001b[1;32mc:\\Users\\kaush\\pyenv\\ml_env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaush\\pyenv\\ml_env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\kaush\\pyenv\\ml_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaush\\pyenv\\ml_env\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\kaush\\pyenv\\ml_env\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\kaush\\pyenv\\ml_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaush\\pyenv\\ml_env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    198\u001b[0m         X,\n\u001b[0;32m    199\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    203\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kaush\\pyenv\\ml_env\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m_tree.pyx:153\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:268\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:923\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._add_node\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:892\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._resize_c\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_utils.pyx:29\u001b[0m, in \u001b[0;36msklearn.tree._utils.safe_realloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: could not allocate 1572864000 bytes"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_train = source_df['Website'].values\n",
    "y_test = target_df['Website'].values\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report for Random Forest:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
